{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOrS4cMb0/rcGM1xo5t1X8Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cyt59LNduyzb","executionInfo":{"status":"ok","timestamp":1706794335051,"user_tz":0,"elapsed":82026,"user":{"displayName":"Matthew Howling","userId":"08564825515102888696"}},"outputId":"701f30bb-e8cb-4bbc-be97-3d4aeb60782e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Python 3.10.12\n","Collecting pybullet\n","  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pybullet\n","Successfully installed pybullet-3.2.6\n","Collecting gymnasium\n","  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.23.5)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n","Collecting farama-notifications>=0.0.1 (from gymnasium)\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Installing collected packages: farama-notifications, gymnasium\n","Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n","Collecting urdfpy\n","  Downloading urdfpy-0.0.22-py3-none-any.whl (26 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from urdfpy) (4.9.4)\n","Collecting networkx==2.2 (from urdfpy)\n","  Downloading networkx-2.2.zip (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from urdfpy) (1.23.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from urdfpy) (9.4.0)\n","Collecting pycollada==0.6 (from urdfpy)\n","  Downloading pycollada-0.6.tar.gz (103 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pyrender>=0.1.20 (from urdfpy)\n","  Downloading pyrender-0.1.45-py3-none-any.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from urdfpy) (1.11.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from urdfpy) (1.16.0)\n","Collecting trimesh (from urdfpy)\n","  Downloading trimesh-4.1.0-py3-none-any.whl (689 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m690.0/690.0 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from networkx==2.2->urdfpy) (4.4.2)\n","Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from pycollada==0.6->urdfpy) (2.8.2)\n","Collecting freetype-py (from pyrender>=0.1.20->urdfpy)\n","  Downloading freetype_py-2.4.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from pyrender>=0.1.20->urdfpy) (2.31.6)\n","Collecting pyglet>=1.4.10 (from pyrender>=0.1.20->urdfpy)\n","  Downloading pyglet-2.0.10-py3-none-any.whl (858 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m858.3/858.3 kB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting PyOpenGL==3.1.0 (from pyrender>=0.1.20->urdfpy)\n","  Downloading PyOpenGL-3.1.0.zip (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: networkx, pycollada, PyOpenGL\n","  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for networkx: filename=networkx-2.2-py2.py3-none-any.whl size=1526911 sha256=19c205103c6ab188f3adfbfc5748c2e4b26ec6c04120e1cc01204bc04a7e9413\n","  Stored in directory: /root/.cache/pip/wheels/60/ee/2d/07b325c2cbb2ca33e9ca40ceffa86c4f3fa031955a98219159\n","  Building wheel for pycollada (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycollada: filename=pycollada-0.6-py3-none-any.whl size=122852 sha256=26b08ff146fa95e231cd62fcabcc2d9849b1374713ff6811bf8212c61dd15ba6\n","  Stored in directory: /root/.cache/pip/wheels/b1/55/a8/5690b7ffc9b69f87438a69e754d97efc35a08ac7ae80385a6c\n","  Building wheel for PyOpenGL (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyOpenGL: filename=PyOpenGL-3.1.0-py3-none-any.whl size=1745193 sha256=39bf6b0f578c845e22a4d87786398fe65d872ab3c295f334a0b7f753f3fa4079\n","  Stored in directory: /root/.cache/pip/wheels/a1/3c/d2/1f9533f908d86176637521e533c6cdb2d4e48b59003b5c3f19\n","Successfully built networkx pycollada PyOpenGL\n","Installing collected packages: PyOpenGL, pyglet, trimesh, networkx, freetype-py, pyrender, pycollada, urdfpy\n","  Attempting uninstall: PyOpenGL\n","    Found existing installation: PyOpenGL 3.1.7\n","    Uninstalling PyOpenGL-3.1.7:\n","      Successfully uninstalled PyOpenGL-3.1.7\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.2.1\n","    Uninstalling networkx-3.2.1:\n","      Successfully uninstalled networkx-3.2.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed PyOpenGL-3.1.0 freetype-py-2.4.0 networkx-2.2 pycollada-0.6 pyglet-2.0.10 pyrender-0.1.45 trimesh-4.1.0 urdfpy-0.0.22\n","defaultdict(<function QLearningAgent.__init__.<locals>.<lambda> at 0x7853be46db40>, {})\n","10\n","20\n","30\n","40\n","50\n","60\n","70\n","80\n","90\n","100\n","110\n","120\n","130\n","140\n","150\n","160\n","170\n","180\n","190\n","200\n","/content/drive/My Drive/ColabNotebooks/5qlearning/CSVs2/RP3_0.4467_0.9_0.0003_20.csv\n","23.68545889854431\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Update the path based on the location of your file\n","file_path = '/content/drive/My Drive/ColabNotebooks/5qlearning/environmenttt.py'\n","\n","# Add the directory containing the file to sys.path\n","import sys\n","sys.path.append('/content/drive/My Drive/ColabNotebooks/5qlearning')\n","#sys.path.append('/usr/local/lib/python3.7/site-packages/')\n","\n","!python3 --version\n","!pip install pybullet\n","!pip install gymnasium\n","!pip install urdfpy\n","########################\n","\n","import numpy as np\n","import random\n","import pybullet as p\n","from environmenttt import Env\n","from collections import defaultdict\n","import os\n","import matplotlib.pyplot as plt\n","import math\n","import time\n","import csv\n","\n","def export_to_csv(data, filename):\n","    with open(filename, 'w', newline='') as csv_file:\n","        csv_writer = csv.writer(csv_file)\n","\n","        # Write header\n","        csv_writer.writerow(['Key', 'Value'])\n","\n","        # Write data\n","        for key, value in data.items():\n","            csv_writer.writerow([key, value])\n","\n","\n","\n","start_time = time.time()\n","\n","cwd = os.getcwd() # Get the current working directory (cwd)\n","files = os.listdir(cwd) # Get all the files in that directory\n","\n","hours=0\n","minutes=0.2\n","\n","run_time=60*60*hours+60*minutes # # # # # # # # # # # #  # # # # # # # # # # runtime\n","\n","while time.time()<start_time+run_time:\n","#for asdf in range(1, 5):\n","\n","  Current_time=time.time()-start_time\n","  time_fraction=Current_time/run_time\n","\n","  global lr\n","  lr=10**(-0.35)\n","  lr=round(lr, 4)\n","  global df\n","  df=0.9\n","  global eps\n","  #eps=10**(-4)\n","  #eps=(time_fraction)**4\n","  #eps=10**(-0.5*(asdf+1))\n","  #eps=10**(-0.2*(asdf))\n","  eps=10**(-3.5)\n","  eps=round(eps, 4)\n","  global number_of_steps\n","  number_of_steps = 20 # # # # # # # #  # # # # # # # # #  number of steps\n","\n","  reward=0\n","\n","\n","\n","  class QLearningAgent:\n","    def __init__(self, actions):\n","        # actions = [0, 1, 2, 3]\n","        global lr\n","        global df\n","        global eps\n","        self.actions = actions\n","        self.learning_rate = lr #was 0.01\n","        self.discount_factor = df #was 0.9\n","        self.epsilon = eps# was 0.1\n","        self.q_table = defaultdict(lambda: [0.1, 0.1, 0.1, 0.1])\n","        global qarr\n","        qarr=self.q_table\n","\n","    # update q function with sample <s, a, r, s'>\n","    def learn(self, state, action, reward, next_state):\n","        current_q = self.q_table[state][action]\n","        # using Bellman Optimality Equation to update q function\n","        new_q = reward + self.discount_factor * max(self.q_table[next_state])\n","        self.q_table[state][action] += self.learning_rate * (new_q - current_q)\n","        global qarr\n","        qarr=self.q_table\n","        #print(self.q_table)\n","\n","    # get action for the state according to the q function table\n","    # agent pick action of epsilon-greedy policy\n","    def get_action(self, state):\n","        global number_of_steps\n","\n","        #self.epsilon=self.epsilon*0.99995\n","        if np.random.rand() < self.epsilon and n-30<=trial:\n","            # take random action\n","            action = np.random.choice(self.actions)\n","\n","        else:\n","            # take action according to the q function table\n","            state_action = self.q_table[state]\n","            action = self.arg_max(state_action)\n","        return action\n","\n","    @staticmethod\n","    def arg_max(state_action):\n","        max_index_list = []\n","        max_value = state_action[0]\n","        for index, value in enumerate(state_action):\n","            if value > max_value:\n","                max_index_list.clear()\n","                max_value = value\n","                max_index_list.append(index)\n","            elif value == max_value:\n","                max_index_list.append(index)\n","        return random.choice(max_index_list)\n","\n","    def q_table(self):\n","        print(self.q_table)\n","\n","\n","\n","  if __name__ == \"__main__\":\n","      env = Env()\n","      agent = QLearningAgent(actions=list(range(env.n_actions)))\n","\n","      global qarr\n","      print(qarr)\n","\n","      episode_plot=[]\n","      reward_sum_plot=[]\n","      trial_plot=[]\n","\n","      for episode in range(number_of_steps):\n","          state = env.reset()\n","\n","          #global number_of_steps\n","          n=(episode//int(number_of_steps/20))*10+10\n","          if episode%(number_of_steps/20)==0:\n","            print(n)\n","\n","          if episode==(number_of_steps-1):\n","\n","              filename = '/content/drive/My Drive/ColabNotebooks/5qlearning/Q_tables2/RP3_'+str(lr)+'_'+str(df)+'_'+str(eps)+'_'+str(number_of_steps)+'.csv'\n","              export_to_csv(qarr, filename)\n","\n","\n","          for trial in range(n):\n","              env.render()\n","\n","              # take action and proceed one step in the environment\n","              action = agent.get_action(str(state))\n","              next_state, reward, done, reward_sum = env.step(action)\n","\n","              # with sample <s,a,r,s'>, agent learns new q function\n","              agent.learn(str(state), action, reward, str(next_state))\n","\n","              state = next_state\n","              #env.print_value_all(agent.q_table)\n","\n","              if trial==n-1:\n","                  done=True\n","\n","              # if episode ends, then break\n","              if done:\n","\n","                  #print(\"episode:\", episode, \"   trials completed:\", trial, \"    reward:\", reward_sum)\n","\n","                  episode_plot=np.concatenate((episode_plot, [episode]))\n","                  reward_sum_plot = np.concatenate((reward_sum_plot, [reward_sum]))\n","                  trial_plot = np.concatenate((trial_plot, [trial]))\n","\n","\n","                  break\n","\n","\n","\n","\n","\n","  #f=plt.figure(1)\n","  #plt.plot(episode_plot, reward_sum_plot)\n","  #f.show()\n","\n","  #g=plt.figure(2)\n","  #plt.plot(episode_plot, trial_plot)\n","  #g.show()\n","\n","  data_array = np.vstack((episode_plot, reward_sum_plot, trial_plot))\n","\n","  #import csv\n","\n","  # field names\n","  #fields = ['Episode', 'Reward', 'Trials']\n","\n","  # data rows of csv file\n","  rows = data_array\n","\n","  # name of csv file\n","  #filename = \"university_records.csv\"\n","  filename = '/content/drive/My Drive/ColabNotebooks/5qlearning/CSVs2/RP3_'+str(lr)+'_'+str(df)+'_'+str(eps)+'_'+str(number_of_steps)+'.csv'\n","  print(filename)\n","\n","  # writing to csv file\n","  with open(filename, 'w') as csvfile:\n","      # creating a csv writer object\n","      csvwriter = csv.writer(csvfile)\n","\n","      # writing the fields\n","      #csvwriter.writerow(fields)\n","\n","      # writing the data rows\n","      csvwriter.writerows(rows)\n","  #agent.q_table()\n","  print((time.time() - start_time))\n","  #plt.pause(0)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","\n","# Add the directory containing the file to sys.path\n","import sys\n","sys.path.append('/content/drive/My Drive/ColabNotebooks/5qlearning')\n","#sys.path.append('/usr/local/lib/python3.7/site-packages/')\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","\n","directory_path = '/content/drive/My Drive/ColabNotebooks/5qlearning/CSVs/'\n","directory_files = os.listdir(directory_path)\n","i=0\n","#df = pd.Dataframe()\n","for file in directory_files:\n","    data = pd.read_csv(os.path.join(directory_path, file))#, encoding = 'ISO-8859-1',low_memory=False)\n","    #df = pd.concat([df, df_file])\n","    i=i+1\n","    f=plt.figure(i)\n","    #print(data.size)\n","    plt.title(file)\n","    plt.plot(range(1,int((data).size/2)+1), data.iloc[0])\n","    f.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1XHVrWrHD7ykB7NT6XlwraHbZ_kVi5SEt"},"id":"-xK4AJfMvJwV","executionInfo":{"status":"ok","timestamp":1706581594543,"user_tz":0,"elapsed":63284,"user":{"displayName":"Matthew Howling","userId":"08564825515102888696"}},"outputId":"f578ce3c-c290-472c-d8fb-5998e2e20e09"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","\n","# Add the directory containing the file to sys.path\n","import sys\n","sys.path.append('/content/drive/My Drive/ColabNotebooks/5qlearning')\n","#sys.path.append('/usr/local/lib/python3.7/site-packages/')\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","\n","directory_path = '/content/drive/My Drive/ColabNotebooks/5qlearning/CSVs/'\n","directory_files = os.listdir(directory_path)\n","i=0\n","#df = pd.Dataframe()\n","\n","file='RP3_0.7943_0.9_0.0032_X.csv'\n","\n","data = pd.read_csv(os.path.join(directory_path, file))#, encoding = 'ISO-8859-1',low_memory=False)\n","#df = pd.concat([df, df_file])\n","\n","f=plt.figure(12345)\n","#print(data.size)\n","plt.title(file)\n","plt.plot(range(1,int((data).size/2)+1), data.iloc[0])\n","f.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"id":"hyxGSRDUOrcc","executionInfo":{"status":"ok","timestamp":1706750130275,"user_tz":0,"elapsed":22155,"user":{"displayName":"Matthew Howling","userId":"08564825515102888696"}},"outputId":"4fc09740-012f-4e5d-be9a-93ca0b8d00de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjMAAAGzCAYAAADaCpaHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWLElEQVR4nO3dd3gU5doG8Hs3ZVM3vRDSQwkltARC6EIOQYOCFBERQREEgwgoTREVpRzBhofqdygqNjxiQao0UUMLNVSRFhISgpAsJaS+3x+YMZvdTTZ1dpL7d117QWbemXlmtt07886MSgghQERERKRQarkLICIiIqoKhhkiIiJSNIYZIiIiUjSGGSIiIlI0hhkiIiJSNIYZIiIiUjSGGSIiIlI0hhkiIiJSNIYZIiIiUjSGGSIiIlI0hhmqc1avXg2VSiU9rK2t0bBhQ4wcORKpqal6bXv06KHX1t3dHe3bt8fKlStRVFQktVu/fj3i4uLg5+cHjUYDf39/DBo0CMnJyZWqMTU1FY899hhcXV2h1WrRr18/nD9/vtzpLl68qFdv6cfo0aP12iclJaFPnz7QarVwdnZG7969ceTIkTKXkZWVBW9vb6hUKnzzzTd6406cOIHBgwcjNDQUDg4O8PT0RLdu3fDjjz9WeBsAQG5uLqZNmwY/Pz/Y29sjOjoa27ZtM3v6L7/8Eu3atYOdnR28vLwwatQoXL9+vVK1nDp1Cn369IGTkxPc3d0xfPhwZGZmmj39Dz/8INUSGBiI119/HQUFBQbtsrKyMGbMGHh5ecHR0REPPPAADh06ZNBu0qRJaNeuHdzd3eHg4IBmzZrhjTfewO3bt/XaHThwAOPHj0eLFi3g6OiIwMBAPPbYYzh79myFt8GTTz4JOzs7o9POnz8fKpUKGzZsqPB8iWqaivdmorpm9erVePrppzF79myEhITg3r172Lt3L1avXo3g4GAkJyfDzs4OwP0w8+eff2LevHkAgMzMTHzyySc4cuQIpk2bhvnz5wMAZs+ejZMnT6Jt27bw9PREeno6Vq5ciatXryIxMRGtW7c2u77bt2+jXbt2yM7OxksvvQQbGxu8//77EELgyJEj8PDwMDntnTt3sH79eoPhmzdvxtq1a/H1119j8ODBAIBDhw6hc+fOCAgIwHPPPYeioiIsWbIEN27cwP79+9G0aVOjy5gwYQJWrlyJO3fuYN26dRg0aJA0buPGjVi0aBFiYmLg5+eHu3fv4n//+x/27NmD5cuXY8yYMWZvBwAYOnQovvnmG0ycOBGNGzfG6tWrceDAAezcuRNdunQpc9qlS5fi+eefR69evTBgwABcuXIFH374IRo1aoR9+/ZJz7E5rly5grZt28LFxQUTJkzA7du3sXDhQgQGBmL//v2wtbUtc/pNmzYhPj4ePXr0wNChQ3H8+HEsXrwYY8aMwdKlS6V2RUVF6Nq1K44ePYopU6bA09MTS5YsQUpKCpKSktC4cWOpbZcuXRAZGYlGjRrBzs4Ohw8fxsqVKxEVFYVffvkFavX936KDBg3Cb7/9hsGDB6NVq1ZIT0/Hf/7zH9y+fRt79+5Fy5Ytzd4O165dQ3h4ONq0aYMdO3ZIwy9cuIAWLVrgoYceMgi4RBZBENUxq1atEgDEgQMH9IZPmzZNABBfffWVNKx79+6iRYsWeu3u3Lkj/P39haOjo8jLyzO5nPT0dGFtbS2ee+65CtX373//WwAQ+/fvl4adOnVKWFlZiRkzZlRoXsV69eoltFqtyMnJkYY99NBDws3NTVy/fl0alpaWJpycnMSAAQOMzuf48ePC2tpazJ49WwAQ69atK3fZBQUFonXr1qJp06YVqnnfvn0CgFiwYIE0LCcnR4SFhYmYmJgyp83NzRWurq6iW7duoqioSBr+448/CgBi0aJFFapl3Lhxwt7eXly6dEkatm3bNgFALF++vNzpmzdvLlq3bi3y8/OlYa+++qpQqVTi1KlT0rCvvvrKYLteu3ZNuLq6iqFDh5a7nIULFwoAIjExURr222+/idzcXL12Z8+eFRqNRgwbNqzceZa2YsUKAUCsXr1aGtanTx+h1WrFlStXKjw/otrAMEN1jqkws2HDBgFAzJ07VxpmLMwIIcSgQYMEAJGammpyOUVFRUKr1YohQ4ZUqL727duL9u3bGwzv3bu3CAsLq9C8hLgfUNRqtRg5cqTecGdnZzF48GCD9vHx8cLW1lbcunXLYFzPnj3F4MGDxc6dO80OM0II0bdvX+Hj41OhuqdMmSKsrKxEdna23vC5c+cKAOLy5csmp01KShIAxOLFiw3GOTk5iU6dOlWoFm9vb6PbqkmTJqJXr15lTnvixAmjtaSmpgoA4q233pKGDR48WPj4+IjCwkK9tmPGjBEODg7i3r17ZS7rm2++EQDEpk2bylsl0a5dO9GuXbty25VWVFQkOnfuLDw9PcX169fFF198UeGAuHHjRtGtWzfh5OQknJ2dRVRUlFi7dq00/uzZs2LAgAHCx8dHaDQa0bBhQzFkyBCRlZUlhBCiRYsWokePHgbzLSwsFH5+fmLgwIEVXi+q29hnhuqNixcvAgDc3NzKbXv+/HlYWVnB1dVVb3hWVhYyMzNx/PhxPPvss9DpdOjVq5fZNRQVFeHYsWOIiooyGNehQwf8+eefuHXrltnzA+73GykqKsKwYcP0hufm5sLe3t6gvYODA/Ly8gz6+6xbtw6///473nnnnXKXeefOHVy/fh1//vkn3n//fWzatKlC2wEADh8+jCZNmkCr1eoN79ChAwCU2bcnNzcXAIyun729PQ4fPqzX56ksqampuHbtmsnn5PDhw2VOXzy+9PR+fn7w9/fXm/7w4cNo166ddIio5HLu3r1r0FeloKAA169fR1paGrZu3YqZM2fC2dlZ2kamCCGQkZEBT0/PMtsZo1KpsHz5cmRnZ2PcuHGYNGkSoqKikJCQYNb0q1evRnx8PG7cuIEZM2Zg/vz5aNOmDTZv3gwAyMvLQ1xcHPbu3YsXXnhBOhx3/vx5ZGVlAQCGDBmCX375Benp6Xrz/vXXX5GWlobHH3+8wutFdZzcaYqouhXvmfn5559FZmamSElJEd98843w8vISGo1GpKSkSG27d+8uwsPDRWZmpsjMzBSnTp0SEyZMEADEww8/bDDvpk2bCgACgHBychIzZ840+JVdlszMTAFAzJ4922Dc4sWLBQBx+vTpCq1vZGSkaNCggUEdERERokmTJqKgoEAalpubKwIDAwUA8c0330jD7969KwIDA6XDXOXtmXnuueek7aBWq8WgQYPEjRs3KlR3ixYtRM+ePQ2GF+/pWLZsmclpMzMzhUqlEqNGjdIbfvr0aamukofXynLgwAEBQHzyyScG46ZMmSIAlLnHZMGCBSb3JLVv31507NhR+tvR0VE888wzBu1++uknAUBs3rxZb3hiYqK0PgBE06ZNxc6dO8tdp08//VQAEP/973/LbWvKjBkzBABhZWUlkpKSzJomKytLODs7i+joaL1DnkII6XDg4cOHy93rd+bMGQFAfPTRR3rDn3/+eeHk5CTu3r1bwbWhus669mITUe2KjY3V+zs4OBifffYZ/P399YafPn0aXl5e0t8qlQrx8fFYuXKlwTxXrVoFnU6H8+fPY9WqVcjJyUFhYaHBL21TcnJyAAAajcZgXHGH1eI25jh79iySkpIwadIkgxqef/55jBs3DqNGjcLUqVNRVFSEt99+G1evXjVYzvz585Gfn49XXnnFrOVOnDgRgwYNQlpaGr7++msUFhYiLy/P7LqLl1/Z7eDp6YnHHnsMa9asQbNmzfDoo48iNTUVL7zwAmxsbJCfn2/2djT3OTE23pzpdTqdXtuKrHPz5s2xbds23LlzB7///jt+/vlng7OZSjt9+jQSEhIQExODESNGlNm2LMV7dfz8/MzuRLxt2zbcunUL06dPN+iArVKpAAAuLi4AgC1btuChhx6Cg4ODwXyaNGmCNm3a4KuvvsL48eMBAIWFhfjmm2/w8MMPG90jR/UbwwzVWYsXL0aTJk2QnZ2NlStX4pdffjH6RRIcHIyPP/4YKpUKdnZ2aNy4Mby9vY3OMyYmRvr/448/jmbNmgEAFi5caFZNxR/CxYdJSrp3755eG3OsXbsWAAwOMQHA2LFjkZKSggULFmDNmjUA7h8KmTp1KubMmQMnJycA9w+/LViwAIsXL5aGlSc8PBzh4eEAgKeeegq9e/fGww8/jH379klfWuWxt7ev0nZYvnw5cnJy8PLLL+Pll18GcP/U4rCwMHz77bdmr0tVn5Pypi85bUXXWavVSqG8X79++Pzzz9GvXz8cOnTI6Bl06enpiI+Ph4uLC7755htYWVmZrLssKSkpeP3119GyZUskJyfjnXfewcyZM8ud7s8//wSAMsNPSEgIJk+ejPfeew9r165F165d8cgjj+DJJ5+Ugg5w/1DTK6+8gtTUVDRs2BC7du3CtWvXMGTIkEqtE9Vt7DNDdVaHDh0QGxuLgQMH4ocffkDLli3xxBNPGPyydXR0RGxsLHr16oXOnTubDDKlubm5oWfPnlKgMIe7uzs0Go20d6Sk4mF+fn5mz+/zzz9H06ZNERkZaXT8nDlzkJGRgT179uDYsWM4cOCA1JekSZMmAIBZs2ahYcOG6NGjBy5evIiLFy9KfRUyMzNx8eLFcvufDBo0CAcOHKjQtU0aNGhQpe3g4uKC77//HpcuXcLu3btx8eJFfPrpp7h69Sq8vLwM+juVVUfJ5Zaupfg5q+z0Jdejqus8YMAAAPf7SZWWnZ2NBx98EFlZWdi8eXOFXkelFe8N2bRpEwYPHow5c+aYdR0kc7377rs4duwYXnnlFeTk5GDChAlo0aIFrly5IrUZMmQIhBBYt24dAODrr7+Gi4sL+vTpU211UN3BMEP1gpWVFebNm4e0tDT85z//qbb55uTkIDs72+z2arUaEREROHjwoMG4ffv2ITQ0FM7OzmbNa9++fTh37pzRvTIlubm5oUuXLoiIiAAA/Pzzz/D395f2rFy+fBnnzp1DaGgoQkJCEBISgqFDhwK4f6gqJCRE71CJMcWHRyqyLdq0aYOzZ88azHvfvn3SeHMEBgaiW7duCAoKQlZWFpKSkgwOMZalYcOG8PLyMvqc7N+/v9w6iseXnj4tLQ1XrlzRm75NmzY4dOiQQTjct28fHBwcpIBpSm5uLoqKigy287179/Dwww/j7Nmz2LBhA5o3b17mfMqyfv16/PDDD3jrrbfg7++PDz74ALa2tmZ1AA4LCwMAsy4mGRERgZkzZ+KXX37Bnj17kJqaimXLlknjQ0JC0KFDB3z11VcoKCjAt99+i/79+5cZLKkek7vTDlF1M3VqthBCdOjQQfj4+EidE02dml1aRkaGwbALFy4IZ2dn0bVr1wrVN3/+fIP6Tp8+LaysrMS0adP02p46dUrv2iclFXdUPnfunNnL/vLLLwUAsXDhQmnYnj17xPr16/Ueb731lgAgpk6dKtavXy9db8fYdsjLyxPt2rUT9vb2Rk/3NmXv3r0G15m5d++eaNSokYiOjtZre+nSJb3rtZgyduxYoVar9a7hY46xY8cKe3t7vU68P//8swAgli5dKg3Ly8sTp06dEmlpaXrTh4eHi9atW+t1tp45c6ZQqVTi5MmT0rDi7V+y82tmZqZwdXXVO8X/5s2bRq9xVHydmZIdewsKCsQjjzwirK2txU8//VSh9S5Np9MJf39/0bZtW711+fDDDwUA8fXXX+u1P3funN7rLzs7Wzg7O4sOHTqY7ACcnZ2tdz2e4uWq1Wrx8ssv6w1/9913pWv9ABAbN26s0vpR3cUwQ3VOWWFm3bp1el9Q5oYZb29vMXToUPHvf/9brFixQkyZMkW4u7sLOzs78dtvv1WoPp1OJ8LCwoS3t7d45513xPvvvy8CAgKEn5+fuHbtml5bAKJ79+4G8ygoKBA+Pj56Z8qUtnv3btGrVy/x73//W/zf//2fePbZZ4WVlZXo06ePwZdJaabOZurfv7/o2bOneOONN8THH38s3nrrLREeHi4AiHfffdf8jfC3wYMHC2trazFlyhSxfPly0alTJ2FtbS12796t16579+6i9G+vefPmiWHDholFixaJJUuWiN69ewsA4u23365wHZcvXxYeHh4iLCxMLFq0SMydO1e4ubmJiIgIvTOZLly4IACIESNG6E3/448/CpVKJXr27ClWrFghJkyYINRqtRg9erReu4KCAtGxY0fh5OQk3nzzTbF48WLRokUL4ezsrHcW2/r160VAQICYNGmSWLJkifjggw/EwIEDhUqlElFRUXoXyXvxxRels+8+/fRTg0dFFNddOgwWFBSIdu3aCT8/P6HT6aThQUFBIigoSK/t//3f/wkAomXLlmLu3Lli6dKlYuzYseKpp56S1q1hw4Zi4sSJYsmSJWLRokWiffv2wsbGRu9igEIIkZKSIlQqlXB2dhbu7u5lXsSS6jeGGapzygozhYWFIiwsTISFhYmCggKzw8zrr78uoqKihJubm7C2thZ+fn7i8ccfF8eOHatUjSkpKWLQoEFCq9UKJycn0bdvX/HHH38YtDMVZjZv3lzuhczOnTsnevfuLTw9PYVGoxHh4eFi3rx5BleLNcZUmPniiy9EbGys8PHxEdbW1sLNzU3ExsaK77//vvyVNiInJ0e8/PLLwtfXV2g0GtG+fXuD05OFMB5mNmzYIDp06CCcnZ2Fg4OD6Nixo8Geg4pITk4WvXv3Fg4ODsLV1VUMGzZMpKen67UxFWaEuP8l3aZNG6HRaIS/v7+YOXOm0S/fGzduiFGjRgkPDw/h4OAgunfvbvBaPXfunHjqqadEaGiosLe3F3Z2dqJFixbi9ddfF7dv39ZrW7xtTD3MdfDgQWFlZSXGjx9vdPz+/fuFWq0WEyZMkIYZCzNCCPHDDz+ITp06CXt7e6HVakWHDh3EF198IYQQ4vz58+KZZ54RYWFhws7OTri7u4sHHnhA/Pzzz0aX27lzZwFAPPvss2avC9U/vDcTERERKRo7ABMREZGi8TozRNXkxo0bZV44zsrKSu/ifHXV7du3y72wm5eXV6WvgVIRmZmZKCwsNDne1tYW7u7uNV6H3CzpOSGqCTzMRFRNevTogd27d5scHxQUJN0fqi5744038Oabb5bZ5sKFCwgODq7xWoKDg3Hp0iWT47t3745du3bVeB1ys6TnhKgmMMwQVZOkpCTcvHnT5Hh7e3t07ty5FiuSx/nz58u9wFqXLl0MLndfE3777bcyb2vg5uZm8oKDdYklPSdENYFhhoiIiBSNHYCJiIhI0epFB+CioiKkpaXB2dnZ7JvgERERkbyEELh16xb8/PygVpve/1IvwkxaWhoCAgLkLoOIiIgqISUlBf7+/ibH14swU3zjvpSUFGi1WpmrISIiInPodDoEBASUewPeehFmig8tabVahhkiIiKFKa+LCDsAExERkaIxzBAREZGiMcwQERGRojHMEBERkaIxzBAREZGiMcwQERGRojHMEBERkaIxzBAREZGiMcwQERGRojHMEBERkaIxzBAREZGiMcwQERGRotWLG03WlP/+egFXbt4FAAgBrP79IgDgqZggbDmRjgxdLp6KCYKV+v4Nsr47nIpAD0e0auiCT/deAgA83TlYb56rfrs/D1srNfIKi+Bga4UwLye0bKjFF/tT8GBLX9jbWOHbw6lY80wHdG/ihZQbd/HT8at4pLUfOs3fgQeaemHV0x1qZRsQERHJTSWEEHIXUdN0Oh1cXFyQnZ1drXfNHrDkNxy6nFVt86uMi/Pj0frNrcjOydcbfn7uQ1Cry77LKBERkSUz9/ube2aqYGCkP2LCPAAAq3+7iDt5hUbbJTwQhgMXb2L/hRsG4x5t2xB+rnYAgI3H03Hh+p0K11E6yABAkRBQg2GGiIjqPoaZKhgWHST9P/NWLr4+eAUAENvMGz+fuiaNmxIXju+PpEphpl2gq7RH59muIWjh5wIAsLexwsKtZ40uy8/FDmnZ98yurVAIPrlERFQvsANwHVVUJHcFREREtUP2MJOamoonn3wSHh4esLe3R0REBA4ePCiNF0Jg1qxZaNCgAezt7REbG4s//vhDxoqVoajud4UiIiICIHOYuXnzJjp37gwbGxts2rQJJ0+exLvvvgs3NzepzTvvvINFixZh2bJl2LdvHxwdHREXF4d798w/5GJpVKqa78tSyDBDRET1hKzdKv79738jICAAq1atkoaFhIRI/xdC4IMPPsDMmTPRr18/AMAnn3wCHx8ffPfdd3j88cdrvWYiIiKyLLLumfnhhx8QFRWFwYMHw9vbG23btsXHH38sjb9w4QLS09MRGxsrDXNxcUF0dDQSExNNzjc3Nxc6nU7vYUkqs1+mNvbmEBERKZGsYeb8+fNYunQpGjdujC1btmDcuHGYMGEC1qxZAwBIT08HAPj4+OhN5+PjI40zZt68eXBxcZEeAQEBNbcStaQeXA6IiIioUmQNM0VFRWjXrh3mzp2Ltm3bYsyYMRg9ejSWLVtWpfnOmDED2dnZ0iMlJaWaKjaPsdxR21mE2YeIiOoLWcNMgwYN0Lx5c71hzZo1w+XLlwEAvr6+AICMjAy9NhkZGdI4YzQaDbRard7DkvCIERERUfWRNcx07twZZ86c0Rt29uxZBAXdvxhdSEgIfH19sX37dmm8TqfDvn37EBMTU6u1VoSxsFJymIpX5iUiIqo2sp7NNGnSJHTq1Alz587FY489hv3792PFihVYsWIFgPudXidOnIi3334bjRs3RkhICF577TX4+fmhf//+cpZeppo4zMQOwERERMbJGmbat2+P9evXY8aMGZg9ezZCQkLwwQcfYNiwYVKbqVOn4s6dOxgzZgyysrLQpUsXbN68GXZ2djJWXvtMdQBesOW0iQlqsBgiIiILIvvte/r27Yu+ffuaHK9SqTB79mzMnj27FquqYdW4k2Xxzj+rb2ZEREQKJPvtDMg8PMxERERkHMOMDBhLiIiIqg/DTB3QIdjdYJhgpxkiIqonZO8zUx9V5oiRqQ7AWyd1QxMfZ5zPvI2e7+6uYmVERETKwz0zCqdmXxoiIqrnuGemmoR4Okn/b+BqeNq4t7NG+n9DVwcANwzaeDhpDIYVi/B3QVr2vaoVqUD38gtx5WYO1H9nNjcHW7g52spbFBERWRSGmWryTJdgbDiWhqy7+ZgSF47P9t6/JcPoriEAgJgwD7zcuwka+zijQ7A7/nfoisE8BkX6Y1NyOg5fuonIYDfsOpOJuBY+6NLYC/ERDRDgdg6DowIQ98Ev0jSmdszUhXsz5RUUIfy1zXrDrNUq/PhCFzRrYFm3qCAiIvkwzFQTjbUVfprQ1WC4o+b+JlapVBjfs3GZ87CxUuOTZzqYHD+zb3OT4+qiq9k50v/VqvvbsKBI4I9rtxlmiIhIwjCjcPWlx8z7Q9rgxS+PAAAmfHEYE744DAB4rnsoVv56AfmF/+yK0tpZY9XTHRAZ5CZHqUREVMvYAVhmvOmkeWysjL9Ul+8+rxdkAEB3rwB7z/9VG2URlWvMJwcRPP0nZN3Nk7sUojqLYUYmHUPdEebliCY+TuU3LuXZLiHS/01dGbgOdJnRY6X+Zz1DPB0Nxr/xcHMcnBmLfm38arMsonJtPZkBAOj9/i/ltCSiymKYkckXozti26TusDaxx6EscS19pf/LsV9n7/m/sOVEut6woylZ+O5wao0t06pEaHPUWBmMd3GwgaeTRur4/OPRNL3xt+7l49PEi7h2S/+MsO8Op+L4lezqL5iolGu3cuUugajOYp8ZmahUqkpdPM8SPL5iLwDgt+k90dDVHgDQb/FvAIAGLnaIDvWo1HyFEEg8/xcy//7Qv/TXXWmcldU/G8vYobni6+388HeIOZ1+S2/8q+uT8cPRNKxJvISfJ3cHcD+UTfzqCADg4vz4StVMRETyY5hROFOB6GzGLSl0FCt5BtCpqzqj022e2BXhvuadKXQ+87YUZooNWbEXL/RshJd6NzVrHiXtu3ADT3y8z+g4J80/L1Vj61zyMJQx2/7e1X/u2m1p2B8l/k/y2px8FW9tOIWPnmiLdoHsuE1EFcPDTHVU6SAD3A8wxQ9T+nywx+xlLN993ujwj3acQ2FRxXvtZOjuHwLS2lmjcyMP2Fr/8/KMLOcLrrwrISt1L1h9MfazQ0jNysEzqw/IXQoRKRDDjMJV5GyoT57pgE+e6YA3H2lRLcvOyjF9dkZBUVGl5xvh74K1z3bEzPhm0jC1uuRhJkPlhplKV0O1KSevUO4SiEiBeJhJgSr7xdytiRcAwMOpem4HUFaAqMyeGbMZWW55h5lMnfVFlqUuXLmaSOk2J6dDdy8fj0UFyF2K2RhmFE7O7+iyAkLpa7/UtEqcFEYWqJBphkh2Yz9LAgB0CvOAv5uDzNWYh18BVCGixJdNWTtDanLPTGUOM5k7H5JXEcMMkcXIupsvdwlmY5ihCimZUcoKEAWFle8zUxmV6TPDr03LwyxDJK+SP1iV9H5kmKEKMXfPTEEV9syU16nZ2JzL6zPD3TBEROUr+dEtFPSTj31mFKjkToia6DMz5pOD0v/Tdfdw7Eo2ujfxgsZarfdCP3Dxpl7bkoasSETKjRxEBbnB3fGfDsdnM27h4l930SnMQ7p2TIbuHo6WuArvr+euV7hmY3tmhv93H/b8YTiv4pqLLzMPAMHTfwIA9G7uY3IZN+/mITvn/m5XIf65Tk3JW1LcvJsvXfQPAFwdbNAh2B35hUU4m3EbqVk5MMXbWYM2Aa7IvJ2Lw5ezAADOdtbQWFvh+m39q8c+0NQLO89kSsvIupsPd0dbRAW54Y9rt5FXUIQQT0c42N6/WvLp9Fu4fOMuokPckVdYBCeNNexsrJB5Kxd38woAAGczDNen5PBipm7BkZ59D7p7BVKbW/cKcDX7ntG2TXyccP12Hm7cMTwjbswnB6XnprG3k9HXeHFN/2ruI11DqKTW/i7IyS+ELqcA6X+f8l/WrUOK5+fqYANHW2vpeSprmpKvgWK21mrkFZjeK1n8OnOxt4GPVqO37NKKl1083tZajWCP+/0XisQ/10xq4uMktdHaWcPXxc7k8ksquVxfrZ20nQCgR1Mv2P7dES2vsAjZOfmwsVJDl5NvcCgwJ//+GWj2Nv9cmbt43tZqFUK9HHEnt1DapvY2VtI0pdcx2MMBRQK4fOOu3ngAJl8vxpSeb+nh9/KLpGWU5GxnjQYudgbThXg6ooGLHX7/8y8EeTigqY8zgPufIWoVENvMR/obACIauqBBiefh0OWbuH47z+Dz5c/M2/gz8w56N/dBWnYOklNNXzYD+Of9UFyfn4sd0rL/eX0XD/d3s5fe+yWVfN0UKzmPxt5Oeq/poSv24s7fZxg2dLXXu/p6yee0eLt+MKQtmvuZd52y6qYSQkk7kipHp9PBxcUF2dnZ0GprZ0MXf2hNjG2MibFNqnXeSZduYODSRADAr9MegL+bA85n3kbPd3eXOV3xVW5PpGUjftGv1VpTdbs4Px6fJF7ErO9PSH8Xb9PWAa44mpKl1/7nyd3QyNtZakNERLXr2+c7VftFL839/uaeGYWriVOOJ/RqDF/t/V8Vr6w/Lg2f+2iEyWG37uXj0o27cNZYQ6VSYdnuPw3amDO/ylgxPBKNvJ3Nbj8zvhkcbK2NLndkp2A08TE+L5UK8HC0hZOdNQ5duomFW88CAD4fHS21mfDFYVy/rf/rsXg9D168gW/LuX/V3EcjqrQ95j4agb9u5+LkVR26NvaShpec5+BIf4Q30MLexgpWasDTSYOCIoHnPr1/BsNHQ9vqnb5f+qrMJde3pJLtPh8djVe+PY6Lfxn++gWA/46Iwri1h4zuxSi5DV76VxNEBut/OJ5M0+Htn04BAFr5u+CYkXtrvTOoFbycNHjt+2RcuZlTZt0la7dSq2ClUiHv7z5fZU2z6Xg6Pt17yeT48nw+Ohrp2fcw+eujRsc/3yMMXRp7GmxXAFh/KBXrkq5Iw4y1KcueP65j6a4/TY4P9XLEs11CAQCFRUU4kpKNNgEu0NrbwMtZo9f2+u08qFXQ2wNbup43fjhhdA/U56OjkfjnX/hoxzlpWNtAV2nPZMl1MXV1cGPmPNoSIZ6OJl+77249i6RLN41OW3p7GjP30Qj8cjYTm/++R93cRyNw6cYdvQuJGvvci23mg57h3gbDmzfQ4mQZFzMtNjG2MTqEuBut76OhbfHCF4f11qO07w6n4uuDV0zOf0Kvxli0/Q/pby9njbSn2dPJFouGtpXGvfZdMv7MvKO3rEbeFb9xcnVhmFG4ykSZ8vqk9GvjhzCv+y/K4jebt7MGT0QH6g0DIA0rrTjMONpa6bUpnraxt5PR+VVG50aeFWo/OCoALvY2Rpfbt1UDRAW7lzuPEE9HKcx0Cvtn+cEejgZhpng9n4gOLDfMPBEdWKXtYer5KJ5ny4ZaLBjc2mD8zRK776OC3dDAxd6gTbGS61vSy72bYOHWs+gY6o5OYZ4I9XIyGWY6hLhjalxTKZQUe6S1n942aB3garC8kocUH23b0GiYKb4+RujvTlKYMVV3SUHuDigUQrovWFnTpGXdKzfMjO4ago/3XDA6rlOYJ06nm/4Cm9CrMexs9A8VFNejtbORwkzJGhu62pu1npmlbnpZ8lADAAxtH6j3WhoeU+4sTeoU5olG3v8cAhnbPQzLdv+J2Gbe6BTmiWu6f2pxsLVCQo9GePaTg3B1sDFrXYyJj2gAVwfD62kVzy+nRyFGrTE8RD4ptonJZZY8BPNEdCA01mopzDwRHYjk1Gy9MGPsc69zIw+jw1sHuJgVZp7uFAIXBxvp75KHlqJKhX5j63G2xD3r/N3sceVmDl55KBxzN56+X4e/i177YA8H6bXyUu+mevOc0KsxXvzyiNmvuZrGMEMGzD3wWG6n27KWUekpq96Xtzp2ZjVwsceGF7rAxd6m/MYVNCw6EGv3XS6zTYC7PVJumO5/Y4qp57Y6tsnY7mFoG+iGNgGuBuM6hXngwYgGeO275L+Xp8LTnUMMwow5ddR0X25z519eu4MzY+HhaGsyzABlv9dKB5mSWjZ0wbfPd4JfGaGzLKWXG+HvohdmarLj50u9m6BLI09EBt3/8r2Xr3/V517NvPHVmI5obGIPKQD831NRmPz1EamPVkmbXuxqNMiU1DP8/jL+++sFqZ/L2mejER1S/g+ZqqhKp46jr/eWPm9+n94T127lYvnuP032uSrPhhe64NTVW+gY6i6FmdLvv5J7/oeUuoDeI6394O1sh2YNzN8rXpN4NpMilbi0P8/SqfA2qMw1aYxp2dAFAe7Vf0GpWQ83lzoYmlLeeDlYW6nRuZEnHDWGv5HsbKzQpdQeNGNhuKLPTHU9lyWZ+31T3qI9nTQ1euXpdoFuZnf2La286/nUZE9KGys1ujT2hP3fHVRLnlSgwv0v0OhQD73DVqVFBbvBR2u47k4aa70b6ppibBmdG3nC2oKvvlnyh5Ofq73RHw0V4epgi5gwD73XaOnnveSrV13q/apSqRAT5lFucKwtlvvMUY2pzK8uS+olXtVaqrBDqVZorK3QI9yrnFbVuxIVucdX9SyvCtOW+PCV87msjiAl1+kX5V05oSbvRlIW84Okhb+JqdYxzNSQUC9HAMBDEQ2qfd5Xbv7TD6G2v4QsUUW3QU38mieZyPhcKvllVN6eGUu8EvNz3UKl/1v6DxKlKv2aVtJnJcNMDdn0Ylfse6WXyTNjqqJkh7nKKO/L39jrt7pf0tU5v4q+3xT0/jSpsutgcrpa3ibV9Rwo4amMa2H62kWyKZVVLDC7GOjV7J/tqKQv2dpSHT9sDQ4zKWgzM8zUEI21ldFjutWh5GGimnixGftgq+7POjk/O+vzB6GlfGmZ+uA15/BBTV800txZmvs6WvZkpOllyfRSLL/PjIW8UErQv/p4/X0P1yYlbWaLCjPz58+HSqXCxIkTpWH37t1DQkICPDw84OTkhIEDByIjw/CKn/WJBX7O1IiaWs+68EGo/DUwrvR6GXsJqPT+b7kdgP9pZ3nPVuk+MaVLtMTPmJIlWcImra1NNLprCL5+rgrnxleBkroxWEyYOXDgAJYvX45WrVrpDZ80aRJ+/PFHrFu3Drt370ZaWhoGDBggU5WWQe9NXQPzN/tDuirLqMZpK342UxUWXg5L+JAti6n69PZ2VNOrSmXi/2XVUeFlyHhLrprYrV9V5m7X8k4CsMAso7c3Sak/SCpT9qvxzdHBxCnj1b0ZDE/Nrt751ySLCDO3b9/GsGHD8PHHH8PN7Z8L/2RnZ+O///0v3nvvPfTs2RORkZFYtWoVfv/9d+zdu1fGiuVlKb+aarqMmnoj1eQv5dp6bqp7FUrWXV3XGBEm/l+m0h+mxpqUGCjv2UzyLbuqyj+bSZ4PmTI3aYmSLGHbly6hJq45Vdss5bulMiwizCQkJCA+Ph6xsbF6w5OSkpCfn683PDw8HIGBgUhMTDQ5v9zcXOh0Or1HXaL3QVOJN7Wnk2VcF6CySr/flLQrtLrU1XUuvV7GP1tLXmep+reD2RfNU/BTULpPTOkvsdr8UisZnstabJFemJF/45eutSauOSU3JYUb2a8A/OWXX+LQoUM4cOCAwbj09HTY2trC1dVVb7iPjw/S09NNznPevHl48803q7tUi2bqQz0qyA2PtQ/Qu8CSt9YO//dUFBw11tDaW+PZNQf17m5cGy/g6lyEBXyuSSypFmPMuQKwkg4zlUdBn8XVwtz3bnntLHG71fSJD9XJt4ZO/iitpg9T1uSVoKubrHtmUlJS8OKLL2Lt2rWws6u+J3/GjBnIzs6WHikpKdU2b0tT/MVj6uwDtUqFx6ICDE4Rj23ug5gwD7Twc0HbQFeT8x8U6Q8AeLFXYyPLVg43B+XvAi7J0j/My2P6bCYzptULXnJS7pNQ7mEkC/xJrnelYAt/AxRfZ6w2lb4BaH0ja5hJSkrCtWvX0K5dO1hbW8Pa2hq7d+/GokWLYG1tDR8fH+Tl5SErK0tvuoyMDPj6+pqcr0ajgVar1XvUJSWDS7nv6Uq850vO852BrbB7Sg882THIsI6Kz7oqZVVpXgkPNKrGJSqXhX8HmKXkKjjYlr1zuTKra/7r2vK+8M19fsvrM2N5a2be6eKW/vI2tQq6HMN7TJmj5PNdlXvlmWKBmdYkWQ8z9erVC8eP698h+Omnn0Z4eDimTZuGgIAA2NjYYPv27Rg4cCAA4MyZM7h8+TJiYuQ5Vc0SVOQFVtXXt1qtQpBH7f/KqAhzfqVtTjY8LGlno8a9/KJqrYUdgEvOx/j/za3DHK1K3eUXAEZ1CanYTGTU2MdJluWWFwws8UvMnJIssGyz/HT8qtwlKJ6sYcbZ2RktW7bUG+bo6AgPDw9p+KhRozB58mS4u7tDq9XihRdeQExMDDp27ChHyRah9I3ZymJOR7nKfnBZ+q+gkm7nGv7y8XDUIDWr4neeppqz/vAVvPtY6zLblAyvxl7eM+ObVakG81/XVX8H2FipMW9ABGZ8e7z8xtWooJxdM3LtwSvrJpGWeCG/usbDUf9QlZI2uUWczVSW999/H3379sXAgQPRrVs3+Pr64ttvv5W7LFlV5JezOR9KSnrBAve/QmY8GK73d3msrWrn07kmvgSK+y3pLae6bzRpIR2AzbnBYblHVhV2LK0mDg+Up7CcDS3Xqdmrn25vcpw5JZXekt8ndK5aQfXEkmHtMP3BcLSu4p245WRxYWbXrl344IMPpL/t7OywePFi3LhxA3fu3MG3335bZn+Z+qAiHeG6Ni7v7svKIwD0auYt/W1qEzwW9U8IGNTOMBBM7dO0uksr14ePt4G9jRVaGzk8YsprfZsbDlQBj7cPqMbKzFPd2+z9Ifp7YZ7sGFjuNC38tGjk7YSujT2rtZaK6tG0+t9bxfNs5F2zh5+e6FD2dh7RKbhGl1/SI6394O2swYB2DeFsZ7qjfnkBzJjWAa6wt7GqSnkAgLHdw6o0fdjfHYL/1dz4fbre6t/S6PCKigy6f522yf9qUqHpHopoIK3jgLYNpeE8m4lqlpm/moI9HDDSjA+l0i/Y8i7+1PjvD9qSgaK0Fn73dxfHt9K/a7ify/2z1mJLvKljQj3KrbE0V4fyr5Uzuus/d9kd1jEIIZ6OGBL1TwDo16ahwTTezlU7qy6+nLuk92vTECfejCu3Q3JwiX5KLvY2Bl9ujb2dMG9ABPa/0guPtPYzu74WDYyHKDvrfz7wtfbGjz6vHBmF53uY35G6d4kbLPZu4QOPEtc3svo7gT7a1h/n5z6ELo08YWulxkv/0g9Lxa+Xkqyt1Ng6sRs+eaZDuR2AO4Xdf22Vt7Om+PXav21D9Ay/X3cDI8suyc7GCufnPoTtL3WXhj3X/f5rrl+bsp+Tku+Lkv1+Vj/dAXtn9MK2Sd2kYcW/lst6bTV0tQcAxDYz76aWbo62mPV3SA50d0DHEu/BDx9vU+X3QZ8W939wDv57r2JxXcY+W5ztbLB3Ri+891ibMudZ+tBY/7+/dJs10ErP8xAjAX/o38GtSyPD8FscHm2tjH8VLhzcGr9N74mpcU3R+e/pHW3vv1dCPM3vS7h5Yjcceu1fBteiOfv2g9gysRuGdwySAo+bg430OuoQbPzKv8WiQ/Q/O/83rhPOzXkQE4ycfQoA7YLcjA4v6b0hbXD27QdxcX68tM001pYfFWS/zgxVnLl9ZnZNeaDC814+PBKeTmWf4rf22WhsOHYVA40c/ij22aho7DxzDQ+21P8A/m58Z/x27joeKvHBvGRYO6w/nIqVv13AlZvm9WHxdNJg+fBI2NtYmdw71djHGR8+3ga+WjvYWKmx8+UeBm1+mtAFR1OyEezhgJt38xHoUbULXw2PCUaIlxMiGrpg4/GriAo2/PBQq1X4V3MffPh4GzRvoMW/3v/FoM3gSH9czb4nBb2tE7shv6gIr65Pxr4Lf2Fs9zCoVCp4a+3wVr+WaOhmj0fbGoazYpte7IofjqZhXA/jvzBtrdXYMrEbCouEQUDYMrEbTqfr8EBT0+HVmMGRAbD7+1fxw638oFarsOGFLrC1VkNd4tCKWq3Cp6M6IK+wCJq/Q9VXYzoi41YuGpu463zx9O6Otpg3IAI2VmrkFxYhoqF+WHumSwjcHW31vqyN+WJMRxy6dBNdGnmioEigqa8Tepixvmq1CmFeTvjfuE7wdLKFv5sDejf3Nagj1MsR5zPv4P0hrXEiVYeX4/4JbeG+WnwzNka6Ma1vqRC1amR7bD2RbvDDoKT1z3fCzjPX8Ehr06+B0kZ0CkaYtxNa+7vASWON/MIiaO1tKhSOTXl/SBsMOf8XYv4OGY+2bQgvZw2am+gTozbjUFvxeyH07xDxXLdQtPDTom2gG6zUKhy4eAOdwwwDy/QHw9G1iafRYBDXwhefjYpGU1/919nOl3vg0KWbeLRtQ6m2aX3CEezhIN29OzLIDe8Obo1gM0KNjZUa7o6GP8BsrdXSsj8ZFY1PEi9iREwwvJw16BjqgfblhJlh0YFw1FjrrZu1iWAGAK38XfH1czFo6GZf5nxt/w4vY7qFwVtrJ4VFS6YS9aBXlU6ng4uLC7Kzs+vEadoLt5zBf3aeAwAcfu1fcHO0xfnM2+j57m69dhfnx5s1v+c+PYgtJzIqNE1N6PefX3H0SrZUxyeJFzHr+xPS38HTfwJw/5eqqWPhxW2Kp1ECJdZMFZNXUIS8wiI4afj7sSpu3cuHvY1VmV/Ycip+L3cK88Dno+vvSSrVydzvb8t8RVCZ+pf4BV4dfR0dy9lVX1vqfKqmesvWWs0gUw2c7WwsNsiQvPiqUKDq/lCcXU2dz4iIiOTAnwoKpHePkmo4jdZJY20RhzfMvsFfGeNWP90eM79LxsLBZV+rhIiI6g6GGbJYpnpzlXU4qkdTb/w6rWeN1ENERJaJh5mUTlnXBysT+8wQEVFlMMwonMIudlohdXndiKjuUsJ1WeoabnEFqqsn0zO7EJGS/XtgBBp5O2F2P55UUdvYZ0bhigOA0u5HQ0RU1wxpH4gh7cu/JQdVP+6ZISIiIkVjmFG44j0y9eBCzhLugyIiopIYZhSo/sQW4+r7+hMRkT6GGSIiIlI0hhmyHOzETERElcAwo0Al+8fUqa//etTvh4iIqg/DDBERESkawwwREREpGsMMWQ72mSEiokpgmFGgkl1L6tT3P/vMEBFRJTDMEBERkaIxzJDlqFO7mYiIqLYwzCicqm6dnE1ERFRhDDNksdiFhoiIzMEwQxajTwtfAEBDV3uZKyEiIiWxlrsAqh6qOtDfZHTXEIR6OSIqyA0Au9AQEZF5GGYUri594VtbqRH3994ZIiIic/EwkwJp7Wyk/1up61CaISIiqgTumVEgFwcbrH66PWyt1LCxup9HBXvLEhFRPcUwo1A9mnrLXQJVk8beTvjj2m25yyAiUiweZiKSmcaGb0MioqqQ/VN03rx5aN++PZydneHt7Y3+/fvjzJkzem3u3buHhIQEeHh4wMnJCQMHDkRGRoZMFRMREZElkT3M7N69GwkJCdi7dy+2bduG/Px89O7dG3fu3JHaTJo0CT/++CPWrVuH3bt3Iy0tDQMGDJCxaiIiIrIUsveZ2bx5s97fq1evhre3N5KSktCtWzdkZ2fjv//9Lz7//HP07NkTALBq1So0a9YMe/fuRceOHeUom4iIiCyE7HtmSsvOzgYAuLu7AwCSkpKQn5+P2NhYqU14eDgCAwORmJhodB65ubnQ6XR6DyIiIqqbLCrMFBUVYeLEiejcuTNatmwJAEhPT4etrS1cXV312vr4+CA9Pd3ofObNmwcXFxfpERAQUNOlExERkUwsKswkJCQgOTkZX375ZZXmM2PGDGRnZ0uPlJSUaqqQiIiILI3sfWaKjR8/Hhs2bMAvv/wCf39/abivry/y8vKQlZWlt3cmIyMDvr7GL32v0Wig0WhqumQiIiKyALLvmRFCYPz48Vi/fj127NiBkJAQvfGRkZGwsbHB9u3bpWFnzpzB5cuXERMTU9vlEhERkYWRfc9MQkICPv/8c3z//fdwdnaW+sG4uLjA3t4eLi4uGDVqFCZPngx3d3dotVq88MILiImJ4ZlMREREJH+YWbp0KQCgR48eesNXrVqFkSNHAgDef/99qNVqDBw4ELm5uYiLi8OSJUtquVIiIiKyRLKHGXNukGhnZ4fFixdj8eLFtVCRMqlUvHs2ERHVT7L3mSGq73jDcyKiqmGYISIiIkVjmCEiIiJFY5ghIiIiRWOYqSPM6UhNRERUFzHMEBERkaIxzBAREZGiMcwQERGRojHMEBERkaIxzBAREZGiMcwQERGRojHMEBERkaIxzJDihHg4yF0CERFZENnvmk1krv+Ni8E3SVcwNS5c7lKqFW94TkRUNQwzpBiRQe6IDHKXuwwiIrIwPMxUR6j4856IiOophhmyWLzdFBERmYNhhoiIiBSNYYYsFo+cERGRORhmiIiISNEYZoiIiEjRGGaIZMaOzkREVcMwU0cIfiMSEVE9xTBDREREisYwQ0RERIrGMENERESKxjBDREREisYwQ0RERIrGMENERESKxjBDREREisYwQ0RERIqmmDCzePFiBAcHw87ODtHR0di/f7/cJVkUFe/KSERE9ZQiwsxXX32FyZMn4/XXX8ehQ4fQunVrxMXF4dq1a3KXRkRERDJTRJh57733MHr0aDz99NNo3rw5li1bBgcHB6xcuVLu0oiIiEhmFh9m8vLykJSUhNjYWGmYWq1GbGwsEhMTjU6Tm5sLnU6n9yAiIqK6yeLDzPXr11FYWAgfHx+94T4+PkhPTzc6zbx58+Di4iI9AgICaqNUIiIikoHFh5nKmDFjBrKzs6VHSkqK3CURERFRDbGWu4DyeHp6wsrKChkZGXrDMzIy4Ovra3QajUYDjUZTG+URERGRzCx+z4ytrS0iIyOxfft2aVhRURG2b9+OmJgYGSsjqh48q56IqGosfs8MAEyePBkjRoxAVFQUOnTogA8++AB37tzB008/LXdpFkMIIXcJREREslBEmBkyZAgyMzMxa9YspKeno02bNti8ebNBp2AiIiKqfxQRZgBg/PjxGD9+vNxlEBERkYWx+D4zRERERGVhmCGSGbs7ERFVDcMMERERKRrDDBERESkawwwREREpGsNMHaHildeIiKieYpghIiIiRWOYISIiIkVjmCEiIiJFY5ghi8XrrxARkTkYZoiIiEjRGGbIYvEELSIiMgfDDBERESkawwwREREpGsMMERERKRrDTB0heOoPERHVUwwzREREpGgMM0RERKRoDDNERESkaAwzREREpGgMM0Qy48UBiYiqhmGGiIiIFI1hpo5Q8ee9YvGseiKiqmGYISIiIkVjmCEiIiJFY5ghIiIiRWOYISIiIkVjmCEiIiJFY5ghIiIiRWOYISIiIkVjmCEiIiJFky3MXLx4EaNGjUJISAjs7e0RFhaG119/HXl5eXrtjh07hq5du8LOzg4BAQF45513ZKqYiIiILJG1XAs+ffo0ioqKsHz5cjRq1AjJyckYPXo07ty5g4ULFwIAdDodevfujdjYWCxbtgzHjx/HM888A1dXV4wZM0au0i2S4GVkiYionpItzPTp0wd9+vSR/g4NDcWZM2ewdOlSKcysXbsWeXl5WLlyJWxtbdGiRQscOXIE7733HsMMERERAbCwPjPZ2dlwd3eX/k5MTES3bt1ga2srDYuLi8OZM2dw8+ZNk/PJzc2FTqfTexAREVHdZDFh5ty5c/joo4/w3HPPScPS09Ph4+Oj16747/T0dJPzmjdvHlxcXKRHQEBAzRRNREREsqv2MDN9+nSoVKoyH6dPn9abJjU1FX369MHgwYMxevToKtcwY8YMZGdnS4+UlJQqz5OIiIgsU7X3mXnppZcwcuTIMtuEhoZK/09LS8MDDzyATp06YcWKFXrtfH19kZGRoTes+G9fX1+T89doNNBoNBWsnIiIiJSo2sOMl5cXvLy8zGqbmpqKBx54AJGRkVi1ahXUav0dRTExMXj11VeRn58PGxsbAMC2bdvQtGlTuLm5VXfpiqZSqeQugYiISBay9ZlJTU1Fjx49EBgYiIULFyIzMxPp6el6fWGeeOIJ2NraYtSoUThx4gS++uorfPjhh5g8ebJcZRMREZGFke3U7G3btuHcuXM4d+4c/P399cYVXzPFxcUFW7duRUJCAiIjI+Hp6YlZs2bxtGwiIiKSyBZmRo4cWW7fGgBo1aoV9uzZU/MFERERkSJZzKnZRERERJXBMENERESKxjBDREREisYwQ0RERIrGMENERESKxjBDREREisYwQ0RERIrGMENERESKxjBTRxRfNZmIiKi+YZghIiIiRWOYISIiIkVjmCEiIiJFY5ipI1QqldwlEBERyYJhhoiIiBSNYYaIiIgUjWGGiIiIFI1hhoiIiBSNYYaIiIgUjWGGiIiIFI1hhoiIiBSNYYaIiIgUjWGGiIiIFI1hhoiIiBSNYYZIZkLIXQERkbIxzBAREZGiMcwQERGRojHM1BGCxyqIiKieYpghIiIiRWOYqSNUKpXcJVAl8akjIqoahhkiIiJSNIYZIiIiUjSLCDO5ublo06YNVCoVjhw5ojfu2LFj6Nq1K+zs7BAQEIB33nlHniKJiIjIIllEmJk6dSr8/PwMhut0OvTu3RtBQUFISkrCggUL8MYbb2DFihUyVElERESWyFruAjZt2oStW7fif//7HzZt2qQ3bu3atcjLy8PKlStha2uLFi1a4MiRI3jvvfcwZswYmSomIiIiSyLrnpmMjAyMHj0an376KRwcHAzGJyYmolu3brC1tZWGxcXF4cyZM7h586bJ+ebm5kKn0+k9iIiIqG6SLcwIITBy5EiMHTsWUVFRRtukp6fDx8dHb1jx3+np6SbnPW/ePLi4uEiPgICA6iuciIiILEq1h5np06dDpVKV+Th9+jQ++ugj3Lp1CzNmzKjuEjBjxgxkZ2dLj5SUlGpfBhEREVmGau8z89JLL2HkyJFltgkNDcWOHTuQmJgIjUajNy4qKgrDhg3DmjVr4Ovri4yMDL3xxX/7+vqanL9GozGYLxEREdVN1R5mvLy84OXlVW67RYsW4e2335b+TktLQ1xcHL766itER0cDAGJiYvDqq68iPz8fNjY2AIBt27ahadOmcHNzq+7SiYiISIFkO5spMDBQ728nJycAQFhYGPz9/QEATzzxBN58802MGjUK06ZNQ3JyMj788EO8//77tV4vERERWSbZT80ui4uLC7Zu3YqEhARERkbC09MTs2bN4mnZREREJLGYMBMcHAwhhMHwVq1aYc+ePTJUREREREpgEVcAJiIiIqoshpk6ws6GTyUREdVP/AasIxq42CPhgTC5yyAiIqp1DDN1yJS4cLlLoEow0lWMiIgqgGGGiIiIFI1hhoiIiBSNYYaIiIgUjWGGiIiIFI1hhoiIiBSNYYaIiIgUjWGGiIiIFI1hhkhmKpXcFRARKRvDDBERESkawwxZLDsbK7lLICIiBbCWuwAiU/q3aYifjl1FpzAPuUshIiILxjBDFsvWWo01z3SQuwwiIrJwPMxEREREisYwQ0RERIrGMENERESKxjBDREREisYwQ0RERIrGMENERESKxjBDREREisYwQ0RERIrGMEMkMyHkroCISNkYZoiIiEjRGGaIiIhI0RhmiIiISNEYZoiIiEjRGGaIiIhI0RhmiIiISNFkDzM//fQToqOjYW9vDzc3N/Tv319v/OXLlxEfHw8HBwd4e3tjypQpKCgokKdYIiIisjjWci78f//7H0aPHo25c+eiZ8+eKCgoQHJysjS+sLAQ8fHx8PX1xe+//46rV6/iqaeego2NDebOnStj5URERGQpZAszBQUFePHFF7FgwQKMGjVKGt68eXPp/1u3bsXJkyfx888/w8fHB23atMFbb72FadOm4Y033oCtra0cpRMREZEFke0w06FDh5Camgq1Wo22bduiQYMGePDBB/X2zCQmJiIiIgI+Pj7SsLi4OOh0Opw4cUKOsomIiMjCyBZmzp8/DwB44403MHPmTGzYsAFubm7o0aMHbty4AQBIT0/XCzIApL/T09NNzjs3Nxc6nU7vQURERHVTtYeZ6dOnQ6VSlfk4ffo0ioqKAACvvvoqBg4ciMjISKxatQoqlQrr1q2rUg3z5s2Di4uL9AgICKiOVSOqESqV3BUQESlbtfeZeemllzBy5Mgy24SGhuLq1asA9PvIaDQahIaG4vLlywAAX19f7N+/X2/ajIwMaZwpM2bMwOTJk6W/dTodAw0REVEdVe1hxsvLC15eXuW2i4yMhEajwZkzZ9ClSxcAQH5+Pi5evIigoCAAQExMDObMmYNr167B29sbALBt2zZotVq9EFSaRqOBRqOphrUhIiIiSyfb2UxarRZjx47F66+/joCAAAQFBWHBggUAgMGDBwMAevfujebNm2P48OF45513kJ6ejpkzZyIhIYFhhYiIiADIfJ2ZBQsWwNraGsOHD0dOTg6io6OxY8cOuLm5AQCsrKywYcMGjBs3DjExMXB0dMSIESMwe/ZsOcsmIiIiCyJrmLGxscHChQuxcOFCk22CgoKwcePGWqyKiIiIlET22xkQERERVQXDDBERESkawwwREREpGsMMkcyEkLsCIiJlY5ghIiIiRWOYISIiIkVjmCEiIiJFY5ghIiIiRWOYISIiIkVjmCEiIiJFY5ipo17ra/qu4kRERHUJw0wdFeBmL3cJREREtYJhpo5SqVRyl0BERFQrGGaIiIhI0RhmiIiISNEYZoiIiEjRGGaIiIhI0RhmiIiISNEYZoiIiEjRGGaIZMaz6ImIqoZhhoiIiBSNYYaIiIgUjWGGiIiIFI1hhoiIiBSNYaaOYp9SIiKqLxhm6ighdwFkNsEni4ioShhmiIiISNEYZoiIiEjRGGaIiIhI0RhmiIiISNEYZoiIiEjRGGaIiIhI0WQNM2fPnkW/fv3g6ekJrVaLLl26YOfOnXptLl++jPj4eDg4OMDb2xtTpkxBQUGBTBUTERGRpZE1zPTt2xcFBQXYsWMHkpKS0Lp1a/Tt2xfp6ekAgMLCQsTHxyMvLw+///471qxZg9WrV2PWrFlylk1EREQWRLYwc/36dfzxxx+YPn06WrVqhcaNG2P+/Pm4e/cukpOTAQBbt27FyZMn8dlnn6FNmzZ48MEH8dZbb2Hx4sXIy8uTq3QiIiKyILKFGQ8PDzRt2hSffPIJ7ty5g4KCAixfvhze3t6IjIwEACQmJiIiIgI+Pj7SdHFxcdDpdDhx4oTJeefm5kKn0+k9iIiIqG6ylmvBKpUKP//8M/r37w9nZ2eo1Wp4e3tj8+bNcHNzAwCkp6frBRkA0t/Fh6KMmTdvHt58882aK14BeG8mIiKqL6p9z8z06dOhUqnKfJw+fRpCCCQkJMDb2xt79uzB/v370b9/fzz88MO4evVqlWqYMWMGsrOzpUdKSko1rR0RERFZmmrfM/PSSy9h5MiRZbYJDQ3Fjh07sGHDBty8eRNarRYAsGTJEmzbtg1r1qzB9OnT4evri/379+tNm5GRAQDw9fU1OX+NRgONRlO1FSEiIiJFqPYw4+XlBS8vr3Lb3b17FwCgVuvvHFKr1SgqKgIAxMTEYM6cObh27Rq8vb0BANu2bYNWq0Xz5s2ruXIiIiJSItk6AMfExMDNzQ0jRozA0aNHcfbsWUyZMgUXLlxAfHw8AKB3795o3rw5hg8fjqNHj2LLli2YOXMmEhISuOeFiIiIAMgYZjw9PbF582bcvn0bPXv2RFRUFH799Vd8//33aN26NQDAysoKGzZsgJWVFWJiYvDkk0/iqaeewuzZs+Uqm4iIiCyMbGczAUBUVBS2bNlSZpugoCBs3LixlioiIiIipeG9mYiIiEjRGGaIZKbiRYGIiKqEYYaIiIgUjWGmjrK24s99pRBC7gqIiJRN1g7AVP3Gdg/Dqas6dG1c/rV+iIiI6gKGmTpm+oPhcpdARERUq3iYiYiIiBSNYYaIiIgUjWGGiIiIFI1hhoiIiBSNYYaIiIgUjWGGiIiIFI1hhoiIiBSNYYaIiIgUjWGGiIiIFI1hhoiIiBSNYYaIiIgUjWGGiIiIFI1hhoiIiBSNYYaIiIgUjWGGiIiIFI1hhoiIiBSNYYaIiIgUjWGGiIiIFI1hhoiIiBSNYYZIZl0bewIAHGytZK6EiEiZrOUugKi+m/SvJvB3d8ADTb3kLoWISJEYZohkZmdjheEdg+Qug4hIsXiYiYiIiBSNYYaIiIgUjWGGiIiIFK3GwsycOXPQqVMnODg4wNXV1Wiby5cvIz4+Hg4ODvD29saUKVNQUFCg12bXrl1o164dNBoNGjVqhNWrV9dUyURERKRANRZm8vLyMHjwYIwbN87o+MLCQsTHxyMvLw+///471qxZg9WrV2PWrFlSmwsXLiA+Ph4PPPAAjhw5gokTJ+LZZ5/Fli1baqpsIiIiUhiVEELU5AJWr16NiRMnIisrS2/4pk2b0LdvX6SlpcHHxwcAsGzZMkybNg2ZmZmwtbXFtGnT8NNPPyE5OVma7vHHH0dWVhY2b95sdg06nQ4uLi7Izs6GVqutlvUiIiKimmXu97dsfWYSExMREREhBRkAiIuLg06nw4kTJ6Q2sbGxetPFxcUhMTGxzHnn5uZCp9PpPYiIiKhuki3MpKen6wUZANLf6enpZbbR6XTIyckxOe958+bBxcVFegQEBFRz9URERGQpKhRmpk+fDpVKVebj9OnTNVWr2WbMmIHs7GzpkZKSIndJREREVEMqdAXgl156CSNHjiyzTWhoqFnz8vX1xf79+/WGZWRkSOOK/y0eVrKNVquFvb29yXlrNBpoNBqz6iAiIiJlq1CY8fLygpdX9dw/JiYmBnPmzMG1a9fg7e0NANi2bRu0Wi2aN28utdm4caPedNu2bUNMTEy11EBERETKV2N9Zi5fvowjR47g8uXLKCwsxJEjR3DkyBHcvn0bANC7d280b94cw4cPx9GjR7FlyxbMnDkTCQkJ0l6VsWPH4vz585g6dSpOnz6NJUuW4Ouvv8akSZNqqmwiIiJSmBo7NXvkyJFYs2aNwfCdO3eiR48eAIBLly5h3Lhx2LVrFxwdHTFixAjMnz8f1tb/7DDatWsXJk2ahJMnT8Lf3x+vvfZauYe6SuOp2URERMpj7vd3jV9nxhJkZ2fD1dUVKSkpDDNEREQKodPpEBAQgKysLLi4uJhsV6E+M0p169YtAOAp2kRERAp069atMsNMvdgzU1RUhLS0NDg7O0OlUlXbfIsTI/f41D5ue/lw28uH215e3P61TwiBW7duwc/PD2q16W6+9WLPjFqthr+/f43NX6vV8oUtE257+XDby4fbXl7c/rWrrD0yxWS7AjARERFRdWCYISIiIkVjmKkCjUaD119/nVcblgG3vXy47eXDbS8vbn/LVS86ABMREVHdxT0zREREpGgMM0RERKRoDDNERESkaAwzREREpGgMM1WwePFiBAcHw87ODtHR0di/f7/cJSnKvHnz0L59ezg7O8Pb2xv9+/fHmTNn9Nrcu3cPCQkJ8PDwgJOTEwYOHIiMjAy9NpcvX0Z8fDwcHBzg7e2NKVOmoKCgQK/Nrl270K5dO2g0GjRq1AirV6+u6dVTlPnz50OlUmHixInSMG77mpOamoonn3wSHh4esLe3R0REBA4ePCiNF0Jg1qxZaNCgAezt7REbG4s//vhDbx43btzAsGHDoNVq4erqilGjRuH27dt6bY4dO4auXbvCzs4OAQEBeOedd2pl/SxVYWEhXnvtNYSEhMDe3h5hYWF46623UPI8GG57hRJUKV9++aWwtbUVK1euFCdOnBCjR48Wrq6uIiMjQ+7SFCMuLk6sWrVKJCcniyNHjoiHHnpIBAYGitu3b0ttxo4dKwICAsT27dvFwYMHRceOHUWnTp2k8QUFBaJly5YiNjZWHD58WGzcuFF4enqKGTNmSG3Onz8vHBwcxOTJk8XJkyfFRx99JKysrMTmzZtrdX0t1f79+0VwcLBo1aqVePHFF6Xh3PY148aNGyIoKEiMHDlS7Nu3T5w/f15s2bJFnDt3Tmozf/584eLiIr777jtx9OhR8cgjj4iQkBCRk5MjtenTp49o3bq12Lt3r9izZ49o1KiRGDp0qDQ+Oztb+Pj4iGHDhonk5GTxxRdfCHt7e7F8+fJaXV9LMmfOHOHh4SE2bNggLly4INatWyecnJzEhx9+KLXhtlcmhplK6tChg0hISJD+LiwsFH5+fmLevHkyVqVs165dEwDE7t27hRBCZGVlCRsbG7Fu3TqpzalTpwQAkZiYKIQQYuPGjUKtVov09HSpzdKlS4VWqxW5ublCCCGmTp0qWrRoobesIUOGiLi4uJpeJYt369Yt0bhxY7Ft2zbRvXt3Kcxw29ecadOmiS5dupgcX1RUJHx9fcWCBQukYVlZWUKj0YgvvvhCCCHEyZMnBQBx4MABqc2mTZuESqUSqampQgghlixZItzc3KTnonjZTZs2re5VUoz4+HjxzDPP6A0bMGCAGDZsmBCC217JeJipEvLy8pCUlITY2FhpmFqtRmxsLBITE2WsTNmys7MBAO7u7gCApKQk5Ofn623n8PBwBAYGSts5MTERERER8PHxkdrExcVBp9PhxIkTUpuS8yhuw+cKSEhIQHx8vMH24bavOT/88AOioqIwePBgeHt7o23btvj444+l8RcuXEB6errednNxcUF0dLTetnd1dUVUVJTUJjY2Fmq1Gvv27ZPadOvWDba2tlKbuLg4nDlzBjdv3qzp1bRInTp1wvbt23H27FkAwNGjR/Hrr7/iwQcfBMBtr2T14kaT1e369esoLCzU+xAHAB8fH5w+fVqmqpStqKgIEydOROfOndGyZUsAQHp6OmxtbeHq6qrX1sfHB+np6VIbY89D8biy2uh0OuTk5MDe3r4mVsniffnllzh06BAOHDhgMI7bvuacP38eS5cuxeTJk/HKK6/gwIEDmDBhAmxtbTFixAhp2xnbbiW3q7e3t954a2truLu767UJCQkxmEfxODc3txpZP0s2ffp06HQ6hIeHw8rKCoWFhZgzZw6GDRsGANz2CsYwQxYhISEBycnJ+PXXX+UupV5ISUnBiy++iG3btsHOzk7ucuqVoqIiREVFYe7cuQCAtm3bIjk5GcuWLcOIESNkrq5u+/rrr7F27Vp8/vnnaNGiBY4cOYKJEyfCz8+P217heJipEjw9PWFlZWVwZkdGRgZ8fX1lqkq5xo8fjw0bNmDnzp3w9/eXhvv6+iIvLw9ZWVl67UtuZ19fX6PPQ/G4stpotdp6uWcAuH8Y6dq1a2jXrh2sra1hbW2N3bt3Y9GiRbC2toaPjw+3fQ1p0KABmjdvrjesWbNmuHz5MoB/tl1Zny++vr64du2a3viCggLcuHGjQs9PfTNlyhRMnz4djz/+OCIiIjB8+HBMmjQJ8+bNA8Btr2QMM5Vga2uLyMhIbN++XRpWVFSE7du3IyYmRsbKlEUIgfHjx2P9+vXYsWOHwW7ZyMhI2NjY6G3nM2fO4PLly9J2jomJwfHjx/U+XLZt2watVit9YcTExOjNo7hNfX6uevXqhePHj+PIkSPSIyoqCsOGDZP+z21fMzp37mxwCYKzZ88iKCgIABASEgJfX1+97abT6bBv3z69bZ+VlYWkpCSpzY4dO1BUVITo6GipzS+//IL8/HypzbZt29C0adN6e5jj7t27UKv1v/asrKxQVFQEgNte0eTugaxUX375pdBoNGL16tXi5MmTYsyYMcLV1VXvzA4q27hx44SLi4vYtWuXuHr1qvS4e/eu1Gbs2LEiMDBQ7NixQxw8eFDExMSImJgYaXzx6cG9e/cWR44cEZs3bxZeXl5GTw+eMmWKOHXqlFi8eHG9Pz3YmJJnMwnBbV9T9u/fL6ytrcWcOXPEH3/8IdauXSscHBzEZ599JrWZP3++cHV1Fd9//704duyY6Nevn9HTg9u2bSv27dsnfv31V9G4cWO904OzsrKEj4+PGD58uEhOThZffvmlcHBwqNenB48YMUI0bNhQOjX722+/FZ6enmLq1KlSG257ZWKYqYKPPvpIBAYGCltbW9GhQwexd+9euUtSFABGH6tWrZLa5OTkiOeff164ubkJBwcH8eijj4qrV6/qzefixYviwQcfFPb29sLT01O89NJLIj8/X6/Nzp07RZs2bYStra0IDQ3VWwbdVzrMcNvXnB9//FG0bNlSaDQaER4eLlasWKE3vqioSLz22mvCx8dHaDQa0atXL3HmzBm9Nn/99ZcYOnSocHJyElqtVjz99NPi1q1bem2OHj0qunTpIjQajWjYsKGYP39+ja+bJdPpdOLFF18UgYGBws7OToSGhopXX31V7xRqbntlUglR4tKHRERERArDPjNERESkaAwzREREpGgMM0RERKRoDDNERESkaAwzREREpGgMM0RERKRoDDNERESkaAwzREREpGgMM0RERKRoDDNERESkaAwzREREpGgMM0RERKRo/w+9UO3alPQCzwAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Update the path based on the location of your file\n","#file_path = '/content/drive/My Drive/ColabNotebooks/5qlearning/environment.py'\n","\n","# Add the directory containing the file to sys.path\n","import sys\n","sys.path.append('/content/drive/My Drive/ColabNotebooks/5qlearning')\n","#sys.path.append('/usr/local/lib/python3.7/site-packages/')\n","\n","#!python3 --version\n","#!pip install pybullet\n","#!pip install gymnasium\n","#!pip install urdfpy\n","\n","#import numpy as np\n","#import random\n","#import pybullet as p\n","#from environmenttt import Env\n","#from collections import defaultdict\n","#import os\n","#import matplotlib.pyplot as plt\n","#import math\n","#import pandas as pd\n","\n","#cwd = os.getcwd() # Get the current working directory (cwd)\n","#files = os.listdir(cwd) # Get all the files in that directory\n","import pandas as pd\n","from ast import literal_eval\n","def import_from_csv(filename):\n","    data = defaultdict(str)  # Change int to the appropriate type for your values\n","\n","    with open(filename, 'r') as csv_file:\n","        csv_reader = csv.reader(csv_file)\n","\n","        # Skip header\n","        next(csv_reader)\n","\n","        # Read data\n","        for row in csv_reader:\n","            key, value = row\n","            data[key] = literal_eval(value)  # Change int to the appropriate type for your values\n","\n","    return data\n","\n","#global lr\n","lr=0\n","#global df\n","df=0\n","#global eps\n","eps=0\n","#global number_of_steps\n","number_of_steps = 1\n","global ij\n","ij=0\n","\n","\n","\n","\n","\n","reward=0\n","\n","directory_path = '/content/drive/My Drive/ColabNotebooks/5qlearning/Q_tables/'\n","directory_files = os.listdir(directory_path)\n","i=0\n","#df = pd.Dataframe()\n","for filename in directory_files:\n","  print(filename)\n","\n","  if filename[0]=='R':\n","    continue\n","\n","\n","  class QLearningAgent:\n","      def __init__(self, actions):\n","          # actions = [0, 1, 2, 3]\n","          global lr\n","          global df\n","          global eps\n","          self.actions = actions\n","          self.learning_rate = lr #was 0.01\n","          self.discount_factor = df #was 0.9\n","          self.epsilon = eps# was 0.1\n","          #self.q_table = defaultdict(lambda: [0.0, 0.0, 0.0, 0.0])\n","          PREVIOUSQ=import_from_csv(os.path.join(directory_path, filename))\n","          self.q_table = defaultdict(lambda: [0.1, 0.1, 0.1, 0.1], PREVIOUSQ)\n","\n","          ##################################################\n","          global qarr\n","          qarr=self.q_table\n","\n","      # update q function with sample <s, a, r, s'>\n","      def learn(self, state, action, reward, next_state):\n","          current_q = self.q_table[state][action]\n","          #print(state)\n","          xx=7\n","          yy=0\n","          if state!=\"None\":\n","\n","            global g\n","            global ij\n","            g=plt.figure(filename+\"1\")\n","            ij=ij+1\n","            #xx=int(state[1])\n","            #yy=int(state[4])\n","            if state[3]==\",\":\n","              xx=int(str(state[1]+state[2]))\n","              if state[6]==\",\":\n","                yy=int(state[5])\n","              else:\n","                yy=int(str(state[5]+state[6]))\n","\n","            else:\n","              xx=int(state[1])\n","              if state[5]==\",\":\n","                yy=int(state[4])\n","              else:\n","                yy=int(str(state[4]+state[5]))\n","\n","\n","            plt.text(xx, yy, ij, color=\"red\", fontsize=12)\n","            plt.axis([0, 20, 0, 10])\n","            plt.plot(xx, yy, marker = 'o')\n","\n","\n","\n","\n","          # using Bellman Optimality Equation to update q function\n","          new_q = reward + self.discount_factor * max(self.q_table[next_state])\n","          self.q_table[state][action] += self.learning_rate * (new_q - current_q)\n","          global qarr\n","          qarr=self.q_table\n","          #print(self.q_table)\n","\n","      # get action for the state according to the q function table\n","      # agent pick action of epsilon-greedy policy\n","      def get_action(self, state):\n","          #self.epsilon=self.epsilon*0.99995\n","          if np.random.rand() < self.epsilon:\n","              # take random action\n","              action = np.random.choice(self.actions)\n","          else:\n","              # take action according to the q function table\n","              state_action = self.q_table[state]\n","              action = self.arg_max(state_action)\n","          return action\n","\n","      @staticmethod\n","      def arg_max(state_action):\n","          max_index_list = []\n","          max_value = state_action[0]\n","          for index, value in enumerate(state_action):\n","              if value > max_value:\n","                  max_index_list.clear()\n","                  max_value = value\n","                  max_index_list.append(index)\n","              elif value == max_value:\n","                  max_index_list.append(index)\n","          return random.choice(max_index_list)\n","\n","      def q_table(self):\n","          print(self.q_table)\n","\n","\n","\n","  if __name__ == \"__main__\":\n","      env = Env()\n","      agent = QLearningAgent(actions=list(range(env.n_actions)))\n","\n","      #global qarr\n","      print(qarr)\n","\n","      episode_plot=[]\n","      reward_sum_plot=[]\n","      trial_plot=[]\n","\n","\n","\n","\n","\n","      for episode in range(number_of_steps):\n","          state = env.reset()\n","\n","\n","\n","          #global number_of_steps######################################\n","          n=160\n","          local_reward_plot=[]\n","          trigger_25=1\n","          trigger_50=1\n","          trigger_75=1\n","          for trial in range(n):\n","              env.render()\n","\n","              # take action and proceed one step in the environment\n","              action = agent.get_action(str(state))\n","              next_state, reward, done, reward_sum = env.step(action)\n","\n","              if reward_sum>=25*0.6273 and trigger_25==1:\n","                print(\"25% covered after \", trial, \"Trials\")\n","                trigger_25=0\n","\n","              if reward_sum>=50*0.6273 and trigger_50==1:\n","                print(\"50% covered after \", trial, \"Trials\")\n","                trigger_50=0\n","\n","              if reward_sum>=75*0.6273 and trigger_75==1:\n","                print(\"75% covered after \", trial, \"Trials\")\n","                trigger_75=0\n","\n","              # with sample <s,a,r,s'>, agent learns new q function\n","              agent.learn(str(state), action, reward, str(next_state))\n","\n","              state = next_state\n","              #env.print_value_all(agent.q_table)\n","\n","              local_reward_plot = np.concatenate((local_reward_plot, [reward_sum]))\n","\n","              if trial==n-1:\n","                  done=True\n","\n","              # if episode ends, then break\n","              if done:\n","\n","                  print(\"episode:\", episode, \"   trials completed:\", trial, \"    reward:\", reward_sum/0.6273, \"%\")\n","\n","                  episode_plot=np.concatenate((episode_plot, [episode]))\n","                  reward_sum_plot = np.concatenate((reward_sum_plot, [reward_sum]))\n","                  trial_plot = np.concatenate((trial_plot, [trial]))\n","\n","\n","                  break\n","  global g\n","  g.show()\n","\n","\n","  f=plt.figure(filename)\n","  #plt.plot(np.linspace(1, n+1, n), local_reward_plot/0.6273)\n","\n","  ax = f.add_subplot(1, 1, 1)\n","\n","  ax.set_xticks(np.arange(0, 161, 10))\n","  ax.set_xticks(np.arange(0, 161, 2), minor=True)\n","  ax.set_yticks(np.arange(0, 101, 10))\n","  ax.set_yticks(np.arange(0, 101, 2), minor=True)\n","\n","  # Or if you want different settings for the grids:\n","  ax.grid(which='minor', alpha=0.2)\n","  ax.grid(which='major', alpha=0.5)\n","\n","  plt.plot(np.linspace(1, n+1, n), local_reward_plot/0.6905)\n","\n","  plt.title(filename)\n","\n","  data = pd.read_csv('/content/drive/My Drive/ColabNotebooks/5qlearning/max_theoretical.csv')\n","\n","  plt.plot(np.linspace(1, 109, 110), data.iloc[0], 'r--')\n","\n","  f.show()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":262},"id":"-EZUMdbHvJ8L","executionInfo":{"status":"error","timestamp":1706625649050,"user_tz":0,"elapsed":13482,"user":{"displayName":"Matthew Howling","userId":"08564825515102888696"}},"outputId":"b0a3322b-b37a-4846-c90d-ccd2a1862467"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'os' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e656b23322bc>\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mdirectory_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/ColabNotebooks/5qlearning/Q_tables/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mdirectory_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#df = pd.Dataframe()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Update the path based on the location of your file\n","#file_path = '/content/drive/My Drive/ColabNotebooks/5qlearning/environment.py'\n","\n","# Add the directory containing the file to sys.path\n","import sys\n","sys.path.append('/content/drive/My Drive/ColabNotebooks/5qlearning')\n","#sys.path.append('/usr/local/lib/python3.7/site-packages/')\n","\n","!python3 --version\n","!pip install pybullet\n","!pip install gymnasium\n","!pip install urdfpy\n","\n","import numpy as np\n","import random\n","import pybullet as p\n","from environmenttt import Env\n","from collections import defaultdict\n","import os\n","import matplotlib.pyplot as plt\n","import math\n","import pandas as pd\n","import csv\n","\n","cwd = os.getcwd() # Get the current working directory (cwd)\n","files = os.listdir(cwd) # Get all the files in that directory\n","import pandas as pd\n","from ast import literal_eval\n","def import_from_csv(filename):\n","    data = defaultdict(str)  # Change int to the appropriate type for your values\n","\n","    with open(filename, 'r') as csv_file:\n","        csv_reader = csv.reader(csv_file)\n","\n","        # Skip header\n","        next(csv_reader)\n","\n","        # Read data\n","        for row in csv_reader:\n","            key, value = row\n","            data[key] = literal_eval(value)  # Change int to the appropriate type for your values\n","\n","    return data\n","\n","#global lr\n","lr=0\n","#global df\n","df=0\n","#global eps\n","eps=0\n","#global number_of_steps\n","number_of_steps = 1\n","global ij\n","ij=0\n","\n","global continuous_coord_x\n","continuous_coord_x=[]\n","global continuous_coord_y\n","continuous_coord_y=[]\n","\n","\n","\n","reward=0\n","\n","directory_path = '/content/drive/My Drive/ColabNotebooks/5qlearning/Q_tables/'\n","directory_files = os.listdir(directory_path)\n","i=0\n","#df = pd.Dataframe()\n","for filename in directory_files:\n","  print(filename)\n","\n","  if filename[0]=='R':\n","    continue\n","\n","\n","  class QLearningAgent:\n","      def __init__(self, actions):\n","          # actions = [0, 1, 2, 3]\n","          global lr\n","          global df\n","          global eps\n","          self.actions = actions\n","          self.learning_rate = lr #was 0.01\n","          self.discount_factor = df #was 0.9\n","          self.epsilon = eps# was 0.1\n","          #self.q_table = defaultdict(lambda: [0.0, 0.0, 0.0, 0.0])\n","          PREVIOUSQ=import_from_csv(os.path.join(directory_path, filename))\n","          self.q_table = defaultdict(lambda: [0.1, 0.1, 0.1, 0.1], PREVIOUSQ)\n","\n","          ##################################################\n","          global qarr\n","          qarr=self.q_table\n","\n","      # update q function with sample <s, a, r, s'>\n","      def learn(self, state, action, reward, next_state):\n","          current_q = self.q_table[state][action]\n","          #print(state)\n","          xx=7\n","          yy=0\n","          if state!=\"None\":\n","\n","\n","            global ij\n","            g=plt.figure(filename+\"1\")\n","            ij=ij+1\n","            #xx=int(state[1])\n","            #yy=int(state[4])\n","            if state[3]==\",\":\n","              xx=int(str(state[1]+state[2]))\n","              if state[6]==\",\":\n","                yy=int(state[5])\n","              else:\n","                yy=int(str(state[5]+state[6]))\n","\n","            else:\n","              xx=int(state[1])\n","              if state[5]==\",\":\n","                yy=int(state[4])\n","              else:\n","                yy=int(str(state[4]+state[5]))\n","\n","\n","          global continuous_coord_x\n","          global continuous_coord_y\n","\n","          continuous_coord_x= np.concatenate((continuous_coord_x, [xx]))\n","          continuous_coord_y= np.concatenate((continuous_coord_y, [yy]))\n","            #print(xx, yy)\n","\n","\n","          # using Bellman Optimality Equation to update q function\n","          new_q = reward + self.discount_factor * max(self.q_table[next_state])\n","          self.q_table[state][action] += self.learning_rate * (new_q - current_q)\n","          global qarr\n","          qarr=self.q_table\n","          #print(self.q_table)\n","\n","      # get action for the state according to the q function table\n","      # agent pick action of epsilon-greedy policy\n","      def get_action(self, state):\n","          #self.epsilon=self.epsilon*0.99995\n","          if np.random.rand() < self.epsilon:\n","              # take random action\n","              action = np.random.choice(self.actions)\n","          else:\n","              # take action according to the q function table\n","              state_action = self.q_table[state]\n","              action = self.arg_max(state_action)\n","          return action\n","\n","      @staticmethod\n","      def arg_max(state_action):\n","          max_index_list = []\n","          max_value = state_action[0]\n","          for index, value in enumerate(state_action):\n","              if value > max_value:\n","                  max_index_list.clear()\n","                  max_value = value\n","                  max_index_list.append(index)\n","              elif value == max_value:\n","                  max_index_list.append(index)\n","          return random.choice(max_index_list)\n","\n","      def q_table(self):\n","          print(self.q_table)\n","\n","\n","\n","  if __name__ == \"__main__\":\n","      env = Env()\n","      agent = QLearningAgent(actions=list(range(env.n_actions)))\n","\n","      #global qarr\n","      print(qarr)\n","\n","\n","      continuous_coord_x=[]\n","      continuous_coord_y=[]\n","\n","\n","\n","      for episode in range(number_of_steps):\n","          state = env.reset()\n","\n","\n","\n","          #global number_of_steps######################################\n","          n=160\n","          local_reward_plot=[]\n","          trigger_25=1\n","          trigger_50=1\n","          trigger_75=1\n","          for trial in range(n):\n","              env.render()\n","\n","              # take action and proceed one step in the environment\n","              action = agent.get_action(str(state))\n","              next_state, reward, done, reward_sum = env.step(action)\n","\n","              if reward_sum>=25*0.6273 and trigger_25==1:\n","                print(\"25% covered after \", trial, \"Trials\")\n","                trigger_25=0\n","\n","              if reward_sum>=50*0.6273 and trigger_50==1:\n","                print(\"50% covered after \", trial, \"Trials\")\n","                trigger_50=0\n","\n","              if reward_sum>=75*0.6273 and trigger_75==1:\n","                print(\"75% covered after \", trial, \"Trials\")\n","                trigger_75=0\n","\n","              # with sample <s,a,r,s'>, agent learns new q function\n","              agent.learn(str(state), action, reward, str(next_state))\n","\n","              state = next_state\n","              #env.print_value_all(agent.q_table)\n","\n","              local_reward_plot = np.concatenate((local_reward_plot, [reward_sum]))\n","\n","              if trial==n-1:\n","                  done=True\n","\n","              # if episode ends, then break\n","              if done:\n","\n","                  print(\"episode:\", episode, \"   trials completed:\", trial, \"    reward:\", reward_sum/0.6905, \"%\")\n","\n","\n","\n","\n","                  break\n","\n","\n","  h=plt.figure(1)\n","  #print(continuous_coord_x)\n","  plt.plot(continuous_coord_x, continuous_coord_y)\n","  h.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1T6fqFBShRJzIOTrKMDcueyaBKxomHIRA"},"id":"Otle1KlS0yqX","executionInfo":{"status":"ok","timestamp":1707348034285,"user_tz":0,"elapsed":166653,"user":{"displayName":"Matthew Howling","userId":"08564825515102888696"}},"outputId":"ac67405f-ff6a-487e-9f0d-a7cbcbbd8e9f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Update the path based on the location of your file\n","file_path = '/content/drive/My Drive/ColabNotebooks/5qlearning/environment.py'\n","\n","# Add the directory containing the file to sys.path\n","import sys\n","sys.path.append('/content/drive/My Drive/ColabNotebooks/5qlearning')\n","#sys.path.append('/usr/local/lib/python3.7/site-packages/')\n","\n","!python3 --version\n","!pip install pybullet\n","!pip install gymnasium\n","!pip install urdfpy\n","\n","import numpy as np\n","import random\n","import pybullet as p\n","from environmenttt import Env\n","from collections import defaultdict\n","import os\n","import matplotlib.pyplot as plt\n","import math\n","import pandas as pd\n","import csv\n","\n","cwd = os.getcwd() # Get the current working directory (cwd)\n","files = os.listdir(cwd) # Get all the files in that directory\n","from ast import literal_eval\n","def import_from_csv(filename):\n","    data = defaultdict(str)  # Change int to the appropriate type for your values\n","\n","    with open(filename, 'r') as csv_file:\n","        csv_reader = csv.reader(csv_file)\n","\n","        # Skip header\n","        next(csv_reader)\n","\n","        # Read data\n","        for row in csv_reader:\n","            key, value = row\n","            data[key] = literal_eval(value)  # Change int to the appropriate type for your values\n","\n","    return data\n","\n","#global lr\n","lr=0\n","#global df\n","df=0\n","#global eps\n","eps=0\n","#global number_of_steps\n","number_of_steps = 1\n","\n","\n","reward=0\n","\n","directory_path = '/content/drive/My Drive/ColabNotebooks/5qlearning/Q_tables/'\n","directory_files = os.listdir(directory_path)\n","i=0\n","#df = pd.Dataframe()\n","plot_25=np.ones((10, 8))*250\n","#plot_25=np.ones((3, 4))*250\n","plot_50=np.ones((10, 8))*250\n","plot_75=np.ones((10, 8))*250\n","plot_n100=np.zeros((10, 8))\n","plot_n150= np.zeros((10, 8))\n","total_covered_plot=np.zeros((10, 8))\n","\n","for filename in directory_files:\n","  print(filename)\n","  if filename[0]=='R':\n","    continue\n","  xxxx=int(filename[0])\n","  yyyy=int(filename[1])\n","\n","\n","  class QLearningAgent:\n","      def __init__(self, actions):\n","          # actions = [0, 1, 2, 3]\n","          global lr\n","          global df\n","          global eps\n","          self.actions = actions\n","          self.learning_rate = lr #was 0.01\n","          self.discount_factor = df #was 0.9\n","          self.epsilon = eps# was 0.1\n","          #self.q_table = defaultdict(lambda: [0.0, 0.0, 0.0, 0.0])\n","          PREVIOUSQ=import_from_csv(os.path.join(directory_path, filename))\n","          self.q_table = defaultdict(lambda: [0.1, 0.1, 0.1, 0.1], PREVIOUSQ)\n","\n","          ##################################################\n","          global qarr\n","          qarr=self.q_table\n","\n","      # update q function with sample <s, a, r, s'>\n","      def learn(self, state, action, reward, next_state):\n","          current_q = self.q_table[state][action]\n","          #print(state)\n","\n","\n","          # using Bellman Optimality Equation to update q function\n","          new_q = reward + self.discount_factor * max(self.q_table[next_state])\n","          self.q_table[state][action] += self.learning_rate * (new_q - current_q)\n","          global qarr\n","          qarr=self.q_table\n","          #print(self.q_table)\n","\n","      # get action for the state according to the q function table\n","      # agent pick action of epsilon-greedy policy\n","      def get_action(self, state):\n","          #self.epsilon=self.epsilon*0.99995\n","          if np.random.rand() < self.epsilon:\n","              # take random action\n","              action = np.random.choice(self.actions)\n","          else:\n","              # take action according to the q function table\n","              state_action = self.q_table[state]\n","              action = self.arg_max(state_action)\n","          return action\n","\n","      @staticmethod\n","      def arg_max(state_action):\n","          max_index_list = []\n","          max_value = state_action[0]\n","          for index, value in enumerate(state_action):\n","              if value > max_value:\n","                  max_index_list.clear()\n","                  max_value = value\n","                  max_index_list.append(index)\n","              elif value == max_value:\n","                  max_index_list.append(index)\n","          return random.choice(max_index_list)\n","\n","      def q_table(self):\n","          print(self.q_table)\n","\n","\n","\n","  if __name__ == \"__main__\":\n","      env = Env()\n","      agent = QLearningAgent(actions=list(range(env.n_actions)))\n","\n","      #global qarr\n","      print(qarr)\n","\n","      episode_plot=[]\n","      reward_sum_plot=[]\n","      trial_plot=[]\n","\n","      for episode in range(number_of_steps):\n","          state = env.reset()\n","\n","\n","\n","          #global number_of_steps######################################\n","          n=160\n","          mr=0.706387\n","          fs=20\n","          padding=22\n","          local_reward_plot=[]\n","          trigger_25=1\n","          trigger_50=1\n","          trigger_75=1\n","          for trial in range(n):\n","              env.render()\n","\n","              # take action and proceed one step in the environment\n","              action = agent.get_action(str(state))\n","              next_state, reward, done, reward_sum = env.step(action)\n","\n","              if reward_sum>=25*mr and trigger_25==1:\n","                print(\"25% covered after \", trial, \"Trials\")\n","                trigger_25=0\n","                plot_25[xxxx, yyyy]=trial\n","\n","              if reward_sum>=50*mr and trigger_50==1:\n","                print(\"50% covered after \", trial, \"Trials\")\n","                trigger_50=0\n","                plot_50[xxxx, yyyy]=trial\n","\n","              if reward_sum>=75*mr and trigger_75==1:\n","                print(\"75% covered after \", trial, \"Trials\")\n","                trigger_75=0\n","                plot_75[xxxx, yyyy]=trial\n","\n","              if trial==100:\n","                print(reward_sum/mr, \"% covered after 100 Trials\")\n","                plot_n100[xxxx, yyyy]=reward_sum/mr\n","\n","              if trial==150:\n","                print(reward_sum/mr, \"% covered after 150 Trials\")\n","                plot_n150[xxxx, yyyy]=reward_sum/mr\n","\n","              # with sample <s,a,r,s'>, agent learns new q function\n","              agent.learn(str(state), action, reward, str(next_state))\n","\n","              state = next_state\n","              #env.print_value_all(agent.q_table)\n","\n","              local_reward_plot = np.concatenate((local_reward_plot, [reward_sum]))\n","\n","              if trial==n-1:\n","                  done=True\n","\n","              # if episode ends, then break\n","              if done:\n","\n","                  total_covered_plot[xxxx, yyyy]=reward_sum/mr\n","\n","                  print(\"episode:\", episode, \"   trials completed:\", trial, \"    reward:\", reward_sum/mr, \"%\")\n","\n","                  #episode_plot=np.concatenate((episode_plot, [episode]))\n","                  #reward_sum_plot = np.concatenate((reward_sum_plot, [reward_sum]))\n","                  #trial_plot = np.concatenate((trial_plot, [trial]))\n","\n","                  break\n","  #global g\n","  #g.show()\n","\n","\n","  #f=plt.figure(xxxx)\n","\n","\n","  #plt.plot(np.linspace(1, n+1, n), local_reward_plot/mr)\n","\n","  #plt.title(filename)\n","\n","  #data = pd.read_csv('/content/drive/My Drive/ColabNotebooks/5qlearning/max_theoretical.csv')\n","\n","  #plt.plot(np.linspace(1, 109, 110), data.iloc[0], 'r--')\n","\n","  #f.show()\n","\n","#xlab=[0.2, 0.4, 0.6, 0.8]\n","#ylab=[0.35, 0.4, 0.45]\n","\n","xlab=[1.0, 2.0, 3.0, 4.0]\n","ylab=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n","extents=[0.25, 4.25, 0.05, 1.05]\n","\n","#plt.imshow(25/plot_25, cmap='autumn',extent=[0.1,0.9,0.325,0.475],interpolation='nearest',origin='lower',aspect=5, vmin=0, vmax=1.1)\n","plt.imshow(25/plot_25, cmap='autumn', extent=extents, interpolation='nearest',origin='lower',aspect=5, vmin=0, vmax=1.1)\n","\n","cbar = plt.colorbar()\n","cbar.set_label('Area Covered Per Step [%]', rotation=270, labelpad=padding, fontsize=fs)\n","cbar.ax.tick_params(labelsize=fs)\n","plt.xticks(xlab, fontsize=fs)\n","plt.yticks(ylab, fontsize=fs)\n","plt.xlabel(\"-log(ε)\", fontsize=fs)\n","plt.ylabel(\"-log(α)\", fontsize=fs)\n","\n","plt.show()\n","\n","plt.imshow(50/plot_50, cmap='autumn',extent=extents,interpolation='nearest',origin='lower',aspect=5, vmin=0, vmax=1.1)\n","cbar = plt.colorbar()\n","cbar.set_label('Area Covered Per Step [%]', rotation=270, labelpad=padding, fontsize=fs)\n","cbar.ax.tick_params(labelsize=fs)\n","plt.xticks(xlab, fontsize=fs)\n","plt.yticks(ylab, fontsize=fs)\n","plt.xlabel(\"-log(ε)\", fontsize=fs)\n","plt.ylabel(\"-log(α)\", fontsize=fs)\n","plt.show()\n","\n","plt.imshow(75/plot_75, cmap='autumn',extent=extents,interpolation='nearest',origin='lower',aspect=5, vmin=0, vmax=1.1)\n","cbar = plt.colorbar()\n","cbar.set_label('Area Covered Per Step [%]', rotation=270, labelpad=padding, fontsize=fs)\n","cbar.ax.tick_params(labelsize=fs)\n","plt.xticks(xlab, fontsize=fs)\n","plt.yticks(ylab, fontsize=fs)\n","plt.xlabel(\"-log(ε)\", fontsize=fs)\n","plt.ylabel(\"-log(α)\", fontsize=fs)\n","plt.show()\n","\n","plt.imshow(plot_n100/100, cmap='autumn',extent=extents,interpolation='nearest',origin='lower',aspect=5, vmin=0, vmax=1.1)\n","cbar = plt.colorbar()\n","cbar.set_label('Area Covered Per Step [%]', rotation=270, labelpad=padding, fontsize=fs)\n","cbar.ax.tick_params(labelsize=fs)\n","plt.xticks(xlab, fontsize=fs)\n","plt.yticks(ylab, fontsize=fs)\n","plt.xlabel(\"-log(ε)\", fontsize=fs)\n","plt.ylabel(\"-log(α)\", fontsize=fs)\n","plt.show()\n","\n","plt.imshow(plot_n150/150, cmap='autumn',extent=extents,interpolation='nearest',origin='lower',aspect=5, vmin=0, vmax=1.1)\n","cbar = plt.colorbar()\n","cbar.set_label('Area Covered Per Step [%]', rotation=270, labelpad=padding, fontsize=fs)\n","cbar.ax.tick_params(labelsize=fs)\n","plt.xticks(xlab, fontsize=fs)\n","plt.yticks(ylab, fontsize=fs)\n","plt.xlabel(\"-log(ε)\", fontsize=fs)\n","plt.ylabel(\"-log(α)\", fontsize=fs)\n","plt.show()\n","\n","combined = ((25/plot_25)+(50/plot_50)+(75/plot_75)+(plot_n100/100)+(plot_n150/150))/5\n","\n","plt.imshow(combined, cmap='autumn',extent=extents,interpolation='nearest',origin='lower',aspect=5, vmin=0, vmax=1.1)\n","cbar = plt.colorbar()\n","cbar.set_label('Area Covered Per Step [%]', rotation=270, labelpad=padding, fontsize=fs)\n","cbar.ax.tick_params(labelsize=fs)\n","plt.xticks(xlab, rotation=0, fontsize=fs)\n","plt.yticks(ylab, fontsize=fs)\n","plt.xlabel(\"-log(ε)\", fontsize=fs)\n","plt.ylabel(\"-log(α)\", fontsize=fs)\n","plt.show()\n","\n","#plt.imshow(xlab, ylab, total_covered_plot, annot=True,  linewidths=.5, cmap='autumn')\n","#plt.gca().invert_yaxis()\n","#plt.xlabel(\"-log(ε) [-]\")\n","#plt.ylabel(\"-log(α) [-]\")\n","#plt.title( \"25% Heat Map\" )\n","#plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1cZ-R2d7V7XFa1KNVug628iCgHpE6SklF"},"id":"9Ldti7ClN_Md","executionInfo":{"status":"ok","timestamp":1711493268279,"user_tz":0,"elapsed":5049,"user":{"displayName":"Matthew Howling","userId":"08564825515102888696"}},"outputId":"477c0784-6638-4d23-d7f7-de6e0a139960"},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}