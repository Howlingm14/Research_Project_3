{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO5TzEpfqRxa1/+cJTB4535"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBNZNBzrvGOG","outputId":"5e030778-ef57-4d62-a3fd-d6ba5217d0f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Python 3.10.12\n","Requirement already satisfied: pybullet in /usr/local/lib/python3.10/dist-packages (3.2.6)\n","Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.23.5)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.9.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n","Requirement already satisfied: urdfpy in /usr/local/lib/python3.10/dist-packages (0.0.22)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from urdfpy) (4.9.4)\n","Requirement already satisfied: networkx==2.2 in /usr/local/lib/python3.10/dist-packages (from urdfpy) (2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from urdfpy) (1.23.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from urdfpy) (9.4.0)\n","Requirement already satisfied: pycollada==0.6 in /usr/local/lib/python3.10/dist-packages (from urdfpy) (0.6)\n","Requirement already satisfied: pyrender>=0.1.20 in /usr/local/lib/python3.10/dist-packages (from urdfpy) (0.1.45)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from urdfpy) (1.11.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from urdfpy) (1.16.0)\n","Requirement already satisfied: trimesh in /usr/local/lib/python3.10/dist-packages (from urdfpy) (4.1.3)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from networkx==2.2->urdfpy) (4.4.2)\n","Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from pycollada==0.6->urdfpy) (2.8.2)\n","Requirement already satisfied: freetype-py in /usr/local/lib/python3.10/dist-packages (from pyrender>=0.1.20->urdfpy) (2.4.0)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from pyrender>=0.1.20->urdfpy) (2.31.6)\n","Requirement already satisfied: pyglet>=1.4.10 in /usr/local/lib/python3.10/dist-packages (from pyrender>=0.1.20->urdfpy) (2.0.10)\n","Requirement already satisfied: PyOpenGL==3.1.0 in /usr/local/lib/python3.10/dist-packages (from pyrender>=0.1.20->urdfpy) (3.1.0)\n","defaultdict(<function QLearningAgent.__init__.<locals>.<lambda> at 0x7d7038c648b0>, {})\n","10\n","20\n","30\n","40\n","50\n","60\n","70\n","80\n","90\n","100\n","110\n","120\n","130\n","140\n","150\n","160\n","170\n","180\n","190\n","200\n","/content/drive/My Drive/ColabNotebooks/5qlearning/CSVs_moved_central/00RP3_0.7943_0.9_0.3162_3000.csv\n","3163.1036536693573\n","defaultdict(<function QLearningAgent.__init__.<locals>.<lambda> at 0x7d7038c67640>, {})\n","10\n","20\n","30\n","40\n","50\n","60\n","70\n","80\n","90\n","100\n","110\n","120\n","130\n","140\n","150\n","160\n","170\n","180\n","190\n","200\n","/content/drive/My Drive/ColabNotebooks/5qlearning/CSVs_moved_central/01RP3_0.7943_0.9_0.1_3000.csv\n","6375.742803573608\n","defaultdict(<function QLearningAgent.__init__.<locals>.<lambda> at 0x7d7038096a70>, {})\n","10\n","20\n","30\n","40\n","50\n","60\n","70\n","80\n","90\n","100\n","110\n","120\n","130\n","140\n","150\n","160\n","170\n","180\n","190\n","200\n","/content/drive/My Drive/ColabNotebooks/5qlearning/CSVs_moved_central/02RP3_0.7943_0.9_0.0316_3000.csv\n","9522.110746145248\n","defaultdict(<function QLearningAgent.__init__.<locals>.<lambda> at 0x7d7038196f80>, {})\n","10\n","20\n","30\n","40\n","50\n","60\n","70\n","80\n","90\n","100\n","110\n","120\n","130\n","140\n","150\n","160\n","170\n","180\n","190\n","200\n","/content/drive/My Drive/ColabNotebooks/5qlearning/CSVs_moved_central/03RP3_0.7943_0.9_0.01_3000.csv\n","12686.010447263718\n","defaultdict(<function QLearningAgent.__init__.<locals>.<lambda> at 0x7d7037f1e440>, {})\n","10\n","20\n","30\n","40\n","50\n","60\n","70\n","80\n","90\n","100\n","110\n","120\n","130\n","140\n","150\n","160\n","170\n","180\n","190\n","200\n","/content/drive/My Drive/ColabNotebooks/5qlearning/CSVs_moved_central/04RP3_0.7943_0.9_0.0032_3000.csv\n","15909.403785943985\n","defaultdict(<function QLearningAgent.__init__.<locals>.<lambda> at 0x7d7037f9d990>, {})\n","10\n","20\n","30\n","40\n","50\n","60\n","70\n","80\n","90\n","100\n","110\n","120\n","130\n","140\n","150\n","160\n","170\n","180\n","190\n","200\n","/content/drive/My Drive/ColabNotebooks/5qlearning/CSVs_moved_central/05RP3_0.7943_0.9_0.001_3000.csv\n","19075.968688726425\n","defaultdict(<function QLearningAgent.__init__.<locals>.<lambda> at 0x7d7037d52c20>, {})\n","10\n","20\n","30\n","40\n","50\n","60\n","70\n","80\n","90\n","100\n","110\n","120\n","130\n","140\n","150\n","160\n","170\n","180\n","190\n","200\n","/content/drive/My Drive/ColabNotebooks/5qlearning/CSVs_moved_central/06RP3_0.7943_0.9_0.0003_3000.csv\n","22267.042784690857\n","defaultdict(<function QLearningAgent.__init__.<locals>.<lambda> at 0x7d7037f9d630>, {})\n","10\n","20\n","30\n","40\n","50\n","60\n","70\n","80\n","90\n","100\n","110\n","120\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Update the path based on the location of your file\n","file_path = '/content/drive/My Drive/ColabNotebooks/5qlearning/moved_environments/environmentmovedcentral.py'\n","\n","# Add the directory containing the file to sys.path\n","import sys\n","sys.path.append('/content/drive/My Drive/ColabNotebooks/5qlearning/moved_environments/')\n","#sys.path.append('/usr/local/lib/python3.7/site-packages/')\n","\n","!python3 --version\n","!pip install pybullet\n","!pip install gymnasium\n","!pip install urdfpy\n","########################\n","\n","import numpy as np\n","import random\n","import pybullet as p\n","from environmentmovedcentral import Env\n","from collections import defaultdict\n","import os\n","import matplotlib.pyplot as plt\n","import math\n","import time\n","import csv\n","\n","def export_to_csv(data, filename):\n","    with open(filename, 'w', newline='') as csv_file:\n","        csv_writer = csv.writer(csv_file)\n","\n","        # Write header\n","        csv_writer.writerow(['Key', 'Value'])\n","\n","        # Write data\n","        for key, value in data.items():\n","            csv_writer.writerow([key, value])\n","\n","\n","\n","start_time = time.time()\n","\n","cwd = os.getcwd() # Get the current working directory (cwd)\n","files = os.listdir(cwd) # Get all the files in that directory\n","\n","hours=0\n","minutes=0.2\n","\n","run_time=60*60*hours+60*minutes # # # # # # # # # # # #  # # # # # # # # # # runtime\n","\n","#while time.time()<start_time+run_time:\n","\n","for qwerty in range(0, 3):\n","  for asdf in range(8):\n","\n","    Current_time=time.time()-start_time\n","    time_fraction=Current_time/run_time\n","\n","    global lr\n","    lr=10**(-0.1*(qwerty+1))\n","    lr=round(lr, 4)\n","    global df\n","    df=0.9\n","    global eps\n","    #eps=10**(-4)\n","    #eps=(time_fraction)**4\n","    eps=10**(-0.5*(asdf+1))\n","    #eps=10**(-0.2*(asdf))\n","    #eps=10**(-3.5)\n","    eps=round(eps, 4)\n","    global number_of_steps\n","    number_of_steps = 3000 # # # # # # # #  # # # # # # # # #  number of steps\n","\n","    reward=0\n","\n","\n","\n","    class QLearningAgent:\n","      def __init__(self, actions):\n","          # actions = [0, 1, 2, 3]\n","          global lr\n","          global df\n","          global eps\n","          self.actions = actions\n","          self.learning_rate = lr #was 0.01\n","          self.discount_factor = df #was 0.9\n","          self.epsilon = eps# was 0.1\n","          self.q_table = defaultdict(lambda: [0.1, 0.1, 0.1, 0.1])\n","          global qarr\n","          qarr=self.q_table\n","\n","      # update q function with sample <s, a, r, s'>\n","      def learn(self, state, action, reward, next_state):\n","          current_q = self.q_table[state][action]\n","          # using Bellman Optimality Equation to update q function\n","          new_q = reward + self.discount_factor * max(self.q_table[next_state])\n","          self.q_table[state][action] += self.learning_rate * (new_q - current_q)\n","          global qarr\n","          qarr=self.q_table\n","          #print(self.q_table)\n","\n","      # get action for the state according to the q function table\n","      # agent pick action of epsilon-greedy policy\n","      def get_action(self, state):\n","          global number_of_steps\n","\n","          #self.epsilon=self.epsilon*0.99995\n","          if np.random.rand() < self.epsilon and n-30<=trial:\n","              # take random action\n","              action = np.random.choice(self.actions)\n","\n","          else:\n","              # take action according to the q function table\n","              state_action = self.q_table[state]\n","              action = self.arg_max(state_action)\n","          return action\n","\n","      @staticmethod\n","      def arg_max(state_action):\n","          max_index_list = []\n","          max_value = state_action[0]\n","          for index, value in enumerate(state_action):\n","              if value > max_value:\n","                  max_index_list.clear()\n","                  max_value = value\n","                  max_index_list.append(index)\n","              elif value == max_value:\n","                  max_index_list.append(index)\n","          return random.choice(max_index_list)\n","\n","      def q_table(self):\n","          print(self.q_table)\n","\n","\n","\n","    if __name__ == \"__main__\":\n","        env = Env()\n","        agent = QLearningAgent(actions=list(range(env.n_actions)))\n","\n","        global qarr\n","        print(qarr)\n","\n","        episode_plot=[]\n","        reward_sum_plot=[]\n","        trial_plot=[]\n","\n","        for episode in range(number_of_steps):\n","            state = env.reset()\n","\n","            #global number_of_steps\n","            n=(episode//int(number_of_steps/20))*10+10\n","            if episode%(number_of_steps/20)==0:\n","              print(n)\n","\n","            if episode==(number_of_steps-1):\n","\n","                filename = '/content/drive/My Drive/ColabNotebooks/5qlearning/Q_tables_moved_central/'+str(qwerty)+str(asdf)+'RP3_'+str(lr)+'_'+str(df)+'_'+str(eps)+'_'+str(number_of_steps)+'.csv'\n","                export_to_csv(qarr, filename)\n","\n","\n","            for trial in range(n):\n","                env.render()\n","\n","                # take action and proceed one step in the environment\n","                action = agent.get_action(str(state))\n","                next_state, reward, done, reward_sum = env.step(action)\n","\n","                # with sample <s,a,r,s'>, agent learns new q function\n","                agent.learn(str(state), action, reward, str(next_state))\n","\n","                state = next_state\n","                #env.print_value_all(agent.q_table)\n","\n","                if trial==n-1:\n","                    done=True\n","\n","                # if episode ends, then break\n","                if done:\n","\n","                    #print(\"episode:\", episode, \"   trials completed:\", trial, \"    reward:\", reward_sum)\n","\n","                    episode_plot=np.concatenate((episode_plot, [episode]))\n","                    reward_sum_plot = np.concatenate((reward_sum_plot, [reward_sum]))\n","                    trial_plot = np.concatenate((trial_plot, [trial]))\n","\n","\n","                    break\n","\n","\n","\n","\n","\n","    #f=plt.figure(1)\n","    #plt.plot(episode_plot, reward_sum_plot)\n","    #f.show()\n","\n","    #g=plt.figure(2)\n","    #plt.plot(episode_plot, trial_plot)\n","    #g.show()\n","\n","    data_array = np.vstack((episode_plot, reward_sum_plot, trial_plot))\n","\n","    #import csv\n","\n","    # field names\n","    #fields = ['Episode', 'Reward', 'Trials']\n","\n","    # data rows of csv file\n","    rows = data_array\n","\n","    # name of csv file\n","    #filename = \"university_records.csv\"\n","    filename = '/content/drive/My Drive/ColabNotebooks/5qlearning/CSVs_moved_central/'+str(qwerty)+str(asdf)+'RP3_'+str(lr)+'_'+str(df)+'_'+str(eps)+'_'+str(number_of_steps)+'.csv'\n","    print(filename)\n","\n","    # writing to csv file\n","    with open(filename, 'w') as csvfile:\n","        # creating a csv writer object\n","        csvwriter = csv.writer(csvfile)\n","\n","        # writing the fields\n","        #csvwriter.writerow(fields)\n","\n","        # writing the data rows\n","        csvwriter.writerows(rows)\n","    #agent.q_table()\n","    print((time.time() - start_time))\n","    #plt.pause(0)"]}]}