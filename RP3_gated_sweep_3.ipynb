{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN9fsLkpsmXbNWn8hWCKXO0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1nFSNBPNCyUrJgpoLv9X2hePIaIbS95Dg"},"id":"SAQgFx0pe5qo","executionInfo":{"status":"ok","timestamp":1703570762996,"user_tz":0,"elapsed":20766609,"user":{"displayName":"Matthew Howling","userId":"08564825515102888696"}},"outputId":"0ea2074a-e338-4222-f15b-44cc41053de3"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Update the path based on the location of your file\n","file_path = '/content/drive/My Drive/ColabNotebooks/5qlearning/environmenttt.py'\n","\n","# Add the directory containing the file to sys.path\n","import sys\n","sys.path.append('/content/drive/My Drive/ColabNotebooks/5qlearning')\n","#sys.path.append('/usr/local/lib/python3.7/site-packages/')\n","\n","!python3 --version\n","!pip install pybullet\n","!pip install gymnasium\n","!pip install urdfpy\n","########################\n","\n","import numpy as np\n","import random\n","import pybullet as p\n","from environmenttt import Env\n","from collections import defaultdict\n","import os\n","import matplotlib.pyplot as plt\n","import math\n","import time\n","\n","start_time = time.time()\n","\n","cwd = os.getcwd() # Get the current working directory (cwd)\n","files = os.listdir(cwd) # Get all the files in that directory\n","\n","while time.time()<start_time+20000:\n","\n","  Current_time=time.time()-start_time\n","  time_fraction=Current_time/20000\n","\n","  global lr\n","  lr=0.01\n","  global df\n","  df=0.9\n","  global eps\n","  eps=(time_fraction)**4\n","  eps=round(eps, 4)\n","  global number_of_steps\n","  number_of_steps = 1500\n","\n","  reward=0\n","\n","\n","\n","  class QLearningAgent:\n","      def __init__(self, actions):\n","          # actions = [0, 1, 2, 3]\n","          global lr\n","          global df\n","          global eps\n","          self.actions = actions\n","          self.learning_rate = lr #was 0.01\n","          self.discount_factor = df #was 0.9\n","          self.epsilon = eps# was 0.1\n","          self.q_table = defaultdict(lambda: [10.0, 10.0, 10.0, 10.0])\n","          global qarr\n","          qarr=self.q_table\n","\n","      # update q function with sample <s, a, r, s'>\n","      def learn(self, state, action, reward, next_state):\n","          current_q = self.q_table[state][action]\n","          # using Bellman Optimality Equation to update q function\n","          new_q = reward + self.discount_factor * max(self.q_table[next_state])\n","          self.q_table[state][action] += self.learning_rate * (new_q - current_q)\n","          global qarr\n","          qarr=self.q_table\n","          #print(self.q_table)\n","\n","      # get action for the state according to the q function table\n","      # agent pick action of epsilon-greedy policy\n","      def get_action(self, state):\n","          #self.epsilon=self.epsilon*0.99995\n","          if np.random.rand() < self.epsilon:\n","              # take random action\n","              action = np.random.choice(self.actions)\n","          else:\n","              # take action according to the q function table\n","              state_action = self.q_table[state]\n","              action = self.arg_max(state_action)\n","          return action\n","\n","      @staticmethod\n","      def arg_max(state_action):\n","          max_index_list = []\n","          max_value = state_action[0]\n","          for index, value in enumerate(state_action):\n","              if value > max_value:\n","                  max_index_list.clear()\n","                  max_value = value\n","                  max_index_list.append(index)\n","              elif value == max_value:\n","                  max_index_list.append(index)\n","          return random.choice(max_index_list)\n","\n","      def q_table(self):\n","          print(self.q_table)\n","\n","\n","\n","  if __name__ == \"__main__\":\n","      env = Env()\n","      agent = QLearningAgent(actions=list(range(env.n_actions)))\n","\n","      global qarr\n","      print(qarr)\n","\n","      episode_plot=[]\n","      reward_sum_plot=[]\n","      trial_plot=[]\n","\n","      for episode in range(number_of_steps):\n","          state = env.reset()\n","\n","          if episode%200==0:\n","              print(\"Q_table\")\n","              print(qarr)\n","\n","\n","          #global number_of_steps\n","          n=(episode//100)*10+10\n","          if episode%100==0:\n","            print(n)\n","          for trial in range(n):\n","              env.render()\n","\n","              # take action and proceed one step in the environment\n","              action = agent.get_action(str(state))\n","              next_state, reward, done, reward_sum = env.step(action)\n","\n","              # with sample <s,a,r,s'>, agent learns new q function\n","              agent.learn(str(state), action, reward, str(next_state))\n","\n","              state = next_state\n","              #env.print_value_all(agent.q_table)\n","\n","              if trial==n-1:\n","                  done=True\n","\n","              # if episode ends, then break\n","              if done:\n","\n","                  #print(\"episode:\", episode, \"   trials completed:\", trial, \"    reward:\", reward_sum)\n","\n","                  episode_plot=np.concatenate((episode_plot, [episode]))\n","                  reward_sum_plot = np.concatenate((reward_sum_plot, [reward_sum]))\n","                  trial_plot = np.concatenate((trial_plot, [trial]))\n","\n","\n","                  break\n","\n","\n","\n","\n","\n","  f=plt.figure(1)\n","  plt.plot(episode_plot, reward_sum_plot)\n","  f.show()\n","\n","  g=plt.figure(2)\n","  plt.plot(episode_plot, trial_plot)\n","  g.show()\n","\n","  data_array = np.vstack((episode_plot, reward_sum_plot, trial_plot))\n","\n","  import csv\n","\n","  # field names\n","  #fields = ['Episode', 'Reward', 'Trials']\n","\n","  # data rows of csv file\n","  rows = data_array\n","\n","  # name of csv file\n","  #filename = \"university_records.csv\"\n","  filename = '/content/drive/My Drive/ColabNotebooks/5qlearning/CSVs/RP3_'+str(lr)+'_'+str(df)+'_'+str(eps)+'_'+str(number_of_steps)+'.csv'\n","  print(filename)\n","\n","  # writing to csv file\n","  with open(filename, 'w') as csvfile:\n","      # creating a csv writer object\n","      csvwriter = csv.writer(csvfile)\n","\n","      # writing the fields\n","      #csvwriter.writerow(fields)\n","\n","      # writing the data rows\n","      csvwriter.writerows(rows)\n","  #agent.q_table()\n","  print((time.time() - start_time))\n","  #plt.pause(0)"]}]}